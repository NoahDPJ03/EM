{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoahDPJ03/EM/blob/main/EMMC_JN_(UPDATED_8_14_25)_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Expectation Maximization: Responsibility method and Monte Carlo Markov Chain Method**\n",
        "\n",
        "Expectation Maximization (EM) is an algorithm designed for finding the mixes of a certain dataset. A mixed dataset means that data points can cmoe from different distributions. For EM to work, we need to know two things about the data:\n",
        "\n",
        "1. How many distributions are associated with the dat\n",
        "2. What those distributions are\n",
        "\n",
        "For example, say we have a dataset call $H$ that is mixed with a Normal, Exponential, and Uniform distribution. We would need to know that there are 3 distributions and that those distributions are a Normal, Exponential, and a Uniform.\n",
        "\n",
        "There are multiple steps to this algorithm work, in which I will explain each one:\n",
        "\n",
        "1. Initialization, we set each mixture component weight, called $\\pi_j$ for distribution $j$ to a value $\\in [0,1]$ such that all the mixture components added together $= 1$ (so basically a probability distribution of distributions). We also set initial parameters for all the distributions.\n",
        "\n",
        "2. We repeat the following steps until we reach convergence or we have reached the number of iterations desired\n",
        "\n",
        "3. The E-step: We use what we know about the data points, the weights of the distributions, and the pdf's associated with each distributions to give us probabililies that a data point came from a particular distribution, or the number of samples from a particular distribution run\n",
        "\n",
        "4. The M-step: We update the mixing weights by averaging the probabilities that a data point come from a particular distribution over all data points for each component.\n",
        "\n",
        "5. We check for convergence or if we reached number of iterations.\n",
        "\n",
        "There are two strategies in doing Expectation Maximization, and my goal is to analyze each strategy and to look at the pros and cons of each.\n",
        "\n",
        "I will start by explaining the first method which if by computing responsibilities (Normal Method of EM). Responsibilities are the probabililies that a data point came from a particular distribution. I didn't want to say this at the start because the other strategy doesn't use responsibilities, so I thought it would confuse some.\n",
        "\n",
        "The difference between the strategies is how they change in the E-step and M-step. For the normal method, once we have initialized everything, our E-step goes as follows:\n",
        "Compute:\n",
        "\n",
        "$$\n",
        "\\gamma_{ij} = P(z_i = j \\mid x_i, \\theta) = \\frac{\\pi_j \\cdot f_j(x_i)}{\\sum_k \\pi_k \\cdot f_k(x_i)}\n",
        "$$\n",
        "\n",
        " for all combinations or a data point and distribution\n",
        "\n",
        "Where $\\gamma_{ij}$ is the responsibility or probability that data point $x_i$ came from the distribution $j$.\n",
        "\n",
        "We then do the M-step for Normal EM, which is:\n",
        "\n",
        "Update the mixture weights by taking the average over all responsibilities associated with mixture $j$, or:\n",
        "\n",
        "$$\n",
        "\\pi_j = \\frac{1}{n} \\sum_{i=1}^{n} \\gamma_{ij} \\quad\n",
        "$$\n",
        "\n",
        "For an intuitional sense, imagine that we acquire a responsibility super high associated with a data point and distribution (which likely means that the pdf value at the data point was high with respect to the others). This means that the probability the x_i is associated with that distribution is high. Since this is true, it would increase our mixture amount because we have a data point that is extremely \"connected\" to that certain distribution.\n",
        "\n",
        "The next method is the point in which this project came to fruition in the first place.\n",
        "\n",
        "The Expection Maximization Monte Carlo Method\n",
        "\n",
        "This is supposed to approximate the responsibility, or normal EM. The reason why someone may do such a method is because the calculations for the responsibilities may be hard to compute.\n",
        "\n",
        "You approximate the responsibilites by sampling in Monte Carlo style: for all the data points, make a Monte Carlo Markov Chain over for however many iterations, and basing our decision to go to a different node, or more specifically, making an educated guess on what distribution this data point comes from by using the acceptance ratio:\n",
        "$$\n",
        "\\alpha = \\min\\left(1, \\frac{\\pi_{z_{\\text{new}}} \\cdot f_{z_{\\text{new}}}(x)}{\\pi_{z} \\cdot f_{z}(x)} \\right)\n",
        "$$\n",
        "What this becomes are samples of each data point, and for our M-step we look at all the different samples, and compute:\n",
        "\n",
        "$$\n",
        " \\pi_j = \\frac{\\text{number of samples where we get distribution $j$} }{\\text{total number of samples}}\n",
        "$$\n",
        "\n",
        "Methods\n",
        "\n",
        "For my methods in analyzing these two methods, I will first start by implementing them into python and give a couple miniature examples of a mixed dataset and see how these methods favor. I will produce my own dataset to which I know all the true information of: The mixing weights, parameters, distributions, etc. and compare that as well to the results that both methods got.\n",
        "\n",
        "Later on, we will create a random mixing distribution sampler where it creates mixes of distribution sizing from 2 to 8 mixes. The parameters will all be random in a certain predetermined interval for each.\n",
        "\n",
        "To start, we must implement each Method, to which I have done so here:\n",
        "\n",
        "The first I did was the MCMC method..."
      ],
      "metadata": {
        "id": "fe0YRRhSXLol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import functools\n",
        "\n",
        "#EM MCl#########################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "\n",
        "def pick_distribution(answer):\n",
        "\n",
        "  if answer == \"Uniform\":\n",
        "    while True:\n",
        "      try:\n",
        "        a0 = float(input(\"Initial lower bound guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    while True:\n",
        "      try:\n",
        "        b0 = float(input(\"Initial upper bound guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x):\n",
        "      return 1 / (b0 - a0) if a0 <= x <= b0 else 0\n",
        "\n",
        "    return pdf, (a0, b0)\n",
        "\n",
        "  if answer == \"Exponential\":\n",
        "    while True:\n",
        "      try:\n",
        "        theta0 = float(input(\"Enter the mean guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    def pdf(x):\n",
        "      return (1 / theta0) * math.exp(-x / theta0) if x >= 0 else 0\n",
        "\n",
        "    return pdf, (theta0,) # Corrected parameter return\n",
        "\n",
        "  if answer == \"Normal\":\n",
        "    while True:\n",
        "      try:\n",
        "        mu0 = float(input(\"Enter the mean guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    while True:\n",
        "      try:\n",
        "        sigma0 = float(input(\"Enter the standard deviation guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x_val):\n",
        "      return (1 / (sigma0 * math.sqrt(2 * math.pi))) * math.exp(-(x_val - mu0)**2 / (2 * sigma0**2))\n",
        "    return pdf, (mu0, sigma0)\n",
        "\n",
        "  if answer == \"Bernoulli\":\n",
        "    while True:\n",
        "        try:\n",
        "            p = float(input(\"Enter probability of success (0 < p < 1): \"))\n",
        "            if 0 < p < 1:\n",
        "                break\n",
        "            else:\n",
        "                print(\"p must be between 0 and 1.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    def pdf(x):\n",
        "        return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "\n",
        "    return pdf, (p,)\n",
        "\n",
        "  if answer == \"Poisson\":\n",
        "\n",
        "    integer_data = [x for x in data if float(x).is_integer()]\n",
        "    estimated_lambda = np.mean(integer_data) if integer_data else 3.0\n",
        "\n",
        "    print(f\"Suggested lambda (from integer data): {estimated_lambda:.2f}\")\n",
        "    while True:\n",
        "        try:\n",
        "            lambda_val = float(input(\"Enter the Poisson mean (lambda): \"))\n",
        "            if lambda_val > 0:\n",
        "                break\n",
        "            else:\n",
        "                print(\"lambda must be greater than 0.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x):\n",
        "      if x >= 0 and float(x).is_integer():\n",
        "          return (math.exp(-lambda_val) * (lambda_val ** x)) / math.factorial(int(x)) # Corrected condition and factorial input\n",
        "      else:\n",
        "          return 0\n",
        "\n",
        "    return pdf, (lambda_val,)\n",
        "\n",
        "\n",
        "  # More distributions TBC\n",
        "\n",
        "def e_step_MCMC(data, components, steps = 100):\n",
        "  n = len(data)\n",
        "  k = len(components)\n",
        "\n",
        "  z_samples = []\n",
        "\n",
        "  for i in range(n):\n",
        "    x = data[i]\n",
        "\n",
        "    z = np.random.choice(k)\n",
        "\n",
        "    chain = []\n",
        "\n",
        "    for t in range(steps):\n",
        "      if k > 1: # Add check for k > 1\n",
        "        z_new = np.random.choice([j for j in range(k) if j != z])\n",
        "\n",
        "        if components[z_new][\"distr name\"] == \"Poisson\" and not float(x).is_integer():\n",
        "          continue\n",
        "        if components[z_new][\"distr name\"] == \"Bernoulli\" and not float(x).is_integer():\n",
        "          continue\n",
        "\n",
        "        num = components[z_new][\"pi\"] * components[z_new][\"pdf\"](x) # Score function which will idealize the data point with a certain distribution if the associated pi and pdf value\n",
        "        den = components[z][\"pi\"] * components[z][\"pdf\"](x)         # with the data point is more than that of the previous\n",
        "\n",
        "        alpha = min(1, num / den if den > 0 else 1)\n",
        "\n",
        "        if np.random.rand() < alpha:\n",
        "          z = z_new\n",
        "\n",
        "      chain.append(z)\n",
        "\n",
        "    z_samples.append(chain)\n",
        "\n",
        "  return z_samples\n",
        "\n",
        "def m_step_MCMC(z_samples, components):\n",
        "\n",
        "  n = len(data)\n",
        "  k = len(components)\n",
        "\n",
        "  flatz = [z for chain in z_samples for z in chain]\n",
        "\n",
        "  total = len(flatz)\n",
        "\n",
        "  eps = 1e-6\n",
        "  min_weight = 0.05\n",
        "\n",
        "  for i in range(k):\n",
        "    count_i = flatz.count(i)\n",
        "    pi_i = (count_i + eps) / (total)\n",
        "    components[i][\"pi\"] =  max(min_weight, pi_i)  # Updates pi / how much each distribution is mixed with how many exposures we got of the the specific distribution for all the data samples / total\n",
        "                                                 # we give (count_i + e-6) for the case when our samples got us no cases when the data point was associated with pi_i distribution. This would make it so\n",
        "                                                    # that theres no chance for the distribution to be revived no matter the pdf we get exposed to in the e step.\n",
        "\n",
        "  new_total = sum(comp[\"pi\"] for comp in components)\n",
        "\n",
        "  for i in range(k):\n",
        "    components[i][\"pi\"] /= new_total # normalizing because of min_weight\n",
        "\n",
        "  return components\n",
        "\n",
        "def update_params_pdfs(data, components, z_samples):\n",
        "  k = len(components)\n",
        "  n = len(data)\n",
        "\n",
        "  flat_x = [x for i, x in enumerate(data) for j in range(len(z_samples[i]))]\n",
        "  flat_z = [z for chain in z_samples for z in chain]\n",
        "\n",
        "  for i in range(len(components)):\n",
        "      print(f\"Component {i}: {components[i]['distr name']}, count = {flat_z.count(i)}\")\n",
        "\n",
        "  print()\n",
        "\n",
        "  for i in range(k):\n",
        "\n",
        "    spec_data  = [x for x, z in zip(flat_x, flat_z) if z == i] # filters data points into what distribution we think the data points are associated with\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Uniform\":\n",
        "      if spec_data: # Add check for empty list\n",
        "        components[i][\"params\"] = (min(spec_data), max(spec_data))\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Exponential\":\n",
        "      if spec_data: # Add check for empty list\n",
        "        components[i][\"params\"] = (np.mean(spec_data),)\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Normal\":\n",
        "      if spec_data: # Add check for empty list\n",
        "        components[i][\"params\"] = (np.mean(spec_data), np.std(spec_data))\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Bernoulli\":\n",
        "      if spec_data:\n",
        "        components[i][\"params\"] = (np.mean(spec_data),)\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Poisson\":\n",
        "      if spec_data:\n",
        "        components[i][\"params\"] = (np.mean(spec_data),)\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "  for comp in components:\n",
        "      name = comp[\"distr name\"]\n",
        "      params = comp[\"params\"]\n",
        "\n",
        "      if name == \"Normal\":\n",
        "        if len(spec_data) > 5:\n",
        "          mu, sigma = params\n",
        "          def f(x, mu=mu, sigma=sigma):\n",
        "              return (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(-(x - mu)**2 / (2 * sigma**2))\n",
        "          comp[\"pdf\"] = f\n",
        "      elif name == \"Poisson\":\n",
        "          lamb = params[0]\n",
        "          def f(x, lamb=lamb):\n",
        "              if x >= 0 and float(x).is_integer():\n",
        "                  return (math.exp(-lamb) * (lamb ** x)) / math.factorial(int(x))\n",
        "              else:\n",
        "                  return 0\n",
        "          comp[\"pdf\"] = f\n",
        "      elif name == \"Exponential\":\n",
        "          theta = params[0]\n",
        "          def f(x, theta=theta):\n",
        "              return (1 / theta) * math.exp(-x / theta) if x >= 0 else 0\n",
        "          comp[\"pdf\"] = f\n",
        "      elif name == \"Uniform\":\n",
        "          a, b = params\n",
        "          def f(x, a=a, b=b):\n",
        "              return 1 / (b - a) if a <= x <= b else 0\n",
        "          comp[\"pdf\"] = f\n",
        "      elif name == \"Bernoulli\":\n",
        "          p = params[0]\n",
        "          def f(x, p=p):\n",
        "              return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "          comp[\"pdf\"] = f\n",
        "      else:\n",
        "          raise ValueError(f\"Unknown distribution name: {name}\")\n",
        "\n",
        "  return components\n",
        "\n",
        "def compute_log_likelihood(data, components):\n",
        "    log_likelihood = 0\n",
        "    for x in data:\n",
        "        mixture_prob = sum(comp['pi'] * comp['pdf'](x) for comp in components)\n",
        "        if mixture_prob > 0:\n",
        "            log_likelihood += np.log(mixture_prob)\n",
        "    return log_likelihood\n",
        "\n",
        "\n",
        "def EM_MCMC(data, num_iters):\n",
        "\n",
        "  components = []\n",
        "\n",
        "  # data = [0, 1, 8, 6, 2, 4] # Removed hardcoded data\n",
        "\n",
        "  num_components = int(input(\"How many distributions would you like to mix? \"))\n",
        "\n",
        "  components = []\n",
        "  for i in range(num_components):\n",
        "    distr = ''\n",
        "    while distr not in [\"Uniform\", \"Exponential\", \"Normal\", \"Poisson\", \"Bernoulli\"]:\n",
        "      distr = input(f\"Choose distribution {i+1}: \")\n",
        "    pdf_f, param = pick_distribution(distr)\n",
        "    components.append({\"distr name\": distr, \"pdf\": pdf_f, \"params\": param, \"pi\": 1 / num_components}) # --> Start by assuming that each data point has equal\n",
        "                                                                                                          # chance of being associated with one of the distributions.\n",
        "  ll_list = []\n",
        "  for i in range(num_iters):\n",
        "    z_samples = e_step_MCMC(data, components) #\n",
        "    components = m_step_MCMC(z_samples, components)\n",
        "    components = update_params_pdfs(data, components, z_samples)\n",
        "\n",
        "    ll = compute_log_likelihood(data, components)\n",
        "    ll_list.append(ll)\n",
        "    if i > 0:\n",
        "      print(f\"Iteration {i+1}: Log-likelihood = {ll}\")\n",
        "\n",
        "  # plot log likelihood changes\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.scatter(range(len(ll_list)), ll_list, label='Data')\n",
        "\n",
        "  coeffs = np.polyfit(range(len(ll_list)), ll_list, deg=3)\n",
        "  trendline = np.poly1d(coeffs)\n",
        "\n",
        "  plt.plot(range(len(ll_list)), trendline(range(len(ll_list))), color='blue', label='Trendline')\n",
        "\n",
        "  plt.xlabel(\"iteration\")\n",
        "  plt.ylabel(\"log likelihood\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Final parameters:\")\n",
        "\n",
        "  for i in range(len(components)):\n",
        "    print(f\"Component {i+1}: {components[i]['distr name']}\")\n",
        "    print(\"Parameters:\", *(float(x) for x in components[i]['params']))\n",
        "    print(f\"Weight: {float(components[i]['pi'])}\")\n",
        "    print()\n",
        "  return\n",
        "\n",
        "np.random.seed(924)\n",
        "\n",
        "# Generate data\n",
        "n = 300\n",
        "data = []\n",
        "\n",
        "# 40% Normal(2, 0.5)\n",
        "data += list(np.random.normal(loc=2, scale=0.5, size=int(0.4 * n)))\n",
        "\n",
        "# 30% Uniform(0,5)\n",
        "data += list(np.random.uniform(0,5, size=int(0.3 * n)))\n",
        "\n",
        "# 30% Exponential(1.5)\n",
        "data += list(np.random.exponential(scale=1.5, size=int(0.3 * n)))\n",
        "\n",
        "# Optional: Shuffle the data\n",
        "random.shuffle(data)\n",
        "\n",
        "\n",
        "EM_MCMC(data, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hWYpDtyqlXni",
        "outputId": "91f6d116-9d6e-4b73-904b-0fd83547ad5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How many distributions would you like to mix? 3\n",
            "Choose distribution 1: Normal\n",
            "Enter the mean guess: 5\n",
            "Enter the standard deviation guess: 6\n",
            "Choose distribution 2: Normal\n",
            "Enter the mean guess: 1\n",
            "Enter the standard deviation guess: 3\n",
            "Choose distribution 3: Normal\n",
            "Enter the mean guess: 5\n",
            "Enter the standard deviation guess: 6\n",
            "Component 0: Normal, count = 7472\n",
            "Component 1: Normal, count = 15093\n",
            "Component 2: Normal, count = 7435\n",
            "\n",
            "Component 0: Normal, count = 7473\n",
            "Component 1: Normal, count = 15105\n",
            "Component 2: Normal, count = 7422\n",
            "\n",
            "Iteration 2: Log-likelihood = -478.05164292949183\n",
            "Component 0: Normal, count = 7472\n",
            "Component 1: Normal, count = 15083\n",
            "Component 2: Normal, count = 7445\n",
            "\n",
            "Iteration 3: Log-likelihood = -476.2476784648948\n",
            "Component 0: Normal, count = 7461\n",
            "Component 1: Normal, count = 15248\n",
            "Component 2: Normal, count = 7291\n",
            "\n",
            "Iteration 4: Log-likelihood = -474.12014879848317\n",
            "Component 0: Normal, count = 7407\n",
            "Component 1: Normal, count = 15349\n",
            "Component 2: Normal, count = 7244\n",
            "\n",
            "Iteration 5: Log-likelihood = -472.18738444476554\n",
            "Component 0: Normal, count = 7257\n",
            "Component 1: Normal, count = 15634\n",
            "Component 2: Normal, count = 7109\n",
            "\n",
            "Iteration 6: Log-likelihood = -470.65968891057014\n",
            "Component 0: Normal, count = 7190\n",
            "Component 1: Normal, count = 15739\n",
            "Component 2: Normal, count = 7071\n",
            "\n",
            "Iteration 7: Log-likelihood = -469.8460314332839\n",
            "Component 0: Normal, count = 7132\n",
            "Component 1: Normal, count = 15886\n",
            "Component 2: Normal, count = 6982\n",
            "\n",
            "Iteration 8: Log-likelihood = -469.37015771126045\n",
            "Component 0: Normal, count = 7126\n",
            "Component 1: Normal, count = 15994\n",
            "Component 2: Normal, count = 6880\n",
            "\n",
            "Iteration 9: Log-likelihood = -468.9253044194672\n",
            "Component 0: Normal, count = 7028\n",
            "Component 1: Normal, count = 16160\n",
            "Component 2: Normal, count = 6812\n",
            "\n",
            "Iteration 10: Log-likelihood = -468.74237587570417\n",
            "Component 0: Normal, count = 6965\n",
            "Component 1: Normal, count = 16369\n",
            "Component 2: Normal, count = 6666\n",
            "\n",
            "Iteration 11: Log-likelihood = -468.63643466918677\n",
            "Component 0: Normal, count = 6918\n",
            "Component 1: Normal, count = 16495\n",
            "Component 2: Normal, count = 6587\n",
            "\n",
            "Iteration 12: Log-likelihood = -468.45521948639816\n",
            "Component 0: Normal, count = 6810\n",
            "Component 1: Normal, count = 16603\n",
            "Component 2: Normal, count = 6587\n",
            "\n",
            "Iteration 13: Log-likelihood = -468.3675127864687\n",
            "Component 0: Normal, count = 6739\n",
            "Component 1: Normal, count = 16836\n",
            "Component 2: Normal, count = 6425\n",
            "\n",
            "Iteration 14: Log-likelihood = -468.2620457984839\n",
            "Component 0: Normal, count = 6586\n",
            "Component 1: Normal, count = 17045\n",
            "Component 2: Normal, count = 6369\n",
            "\n",
            "Iteration 15: Log-likelihood = -468.17485244736116\n",
            "Component 0: Normal, count = 6517\n",
            "Component 1: Normal, count = 17177\n",
            "Component 2: Normal, count = 6306\n",
            "\n",
            "Iteration 16: Log-likelihood = -468.1115901073784\n",
            "Component 0: Normal, count = 6512\n",
            "Component 1: Normal, count = 17090\n",
            "Component 2: Normal, count = 6398\n",
            "\n",
            "Iteration 17: Log-likelihood = -468.1546847893992\n",
            "Component 0: Normal, count = 6489\n",
            "Component 1: Normal, count = 17119\n",
            "Component 2: Normal, count = 6392\n",
            "\n",
            "Iteration 18: Log-likelihood = -468.13037515844997\n",
            "Component 0: Normal, count = 6480\n",
            "Component 1: Normal, count = 17208\n",
            "Component 2: Normal, count = 6312\n",
            "\n",
            "Iteration 19: Log-likelihood = -468.1095783798064\n",
            "Component 0: Normal, count = 6348\n",
            "Component 1: Normal, count = 17454\n",
            "Component 2: Normal, count = 6198\n",
            "\n",
            "Iteration 20: Log-likelihood = -468.01252308795233\n",
            "Component 0: Normal, count = 6322\n",
            "Component 1: Normal, count = 17490\n",
            "Component 2: Normal, count = 6188\n",
            "\n",
            "Iteration 21: Log-likelihood = -468.00982718143706\n",
            "Component 0: Normal, count = 6290\n",
            "Component 1: Normal, count = 17552\n",
            "Component 2: Normal, count = 6158\n",
            "\n",
            "Iteration 22: Log-likelihood = -468.0041962583567\n",
            "Component 0: Normal, count = 6223\n",
            "Component 1: Normal, count = 17649\n",
            "Component 2: Normal, count = 6128\n",
            "\n",
            "Iteration 23: Log-likelihood = -467.95781299610474\n",
            "Component 0: Normal, count = 6273\n",
            "Component 1: Normal, count = 17633\n",
            "Component 2: Normal, count = 6094\n",
            "\n",
            "Iteration 24: Log-likelihood = -467.9567695882528\n",
            "Component 0: Normal, count = 6258\n",
            "Component 1: Normal, count = 17612\n",
            "Component 2: Normal, count = 6130\n",
            "\n",
            "Iteration 25: Log-likelihood = -467.9550971768\n",
            "Component 0: Normal, count = 6211\n",
            "Component 1: Normal, count = 17763\n",
            "Component 2: Normal, count = 6026\n",
            "\n",
            "Iteration 26: Log-likelihood = -467.91078301676\n",
            "Component 0: Normal, count = 6100\n",
            "Component 1: Normal, count = 17880\n",
            "Component 2: Normal, count = 6020\n",
            "\n",
            "Iteration 27: Log-likelihood = -467.8796950521024\n",
            "Component 0: Normal, count = 6017\n",
            "Component 1: Normal, count = 18074\n",
            "Component 2: Normal, count = 5909\n",
            "\n",
            "Iteration 28: Log-likelihood = -467.82763746670764\n",
            "Component 0: Normal, count = 6074\n",
            "Component 1: Normal, count = 18140\n",
            "Component 2: Normal, count = 5786\n",
            "\n",
            "Iteration 29: Log-likelihood = -467.8116012237707\n",
            "Component 0: Normal, count = 6045\n",
            "Component 1: Normal, count = 18303\n",
            "Component 2: Normal, count = 5652\n",
            "\n",
            "Iteration 30: Log-likelihood = -467.7685856297924\n",
            "Component 0: Normal, count = 6003\n",
            "Component 1: Normal, count = 18401\n",
            "Component 2: Normal, count = 5596\n",
            "\n",
            "Iteration 31: Log-likelihood = -467.74686553122814\n",
            "Component 0: Normal, count = 6005\n",
            "Component 1: Normal, count = 18355\n",
            "Component 2: Normal, count = 5640\n",
            "\n",
            "Iteration 32: Log-likelihood = -467.77338075147384\n",
            "Component 0: Normal, count = 5955\n",
            "Component 1: Normal, count = 18455\n",
            "Component 2: Normal, count = 5590\n",
            "\n",
            "Iteration 33: Log-likelihood = -467.72015920012456\n",
            "Component 0: Normal, count = 5934\n",
            "Component 1: Normal, count = 18629\n",
            "Component 2: Normal, count = 5437\n",
            "\n",
            "Iteration 34: Log-likelihood = -467.67028111668907\n",
            "Component 0: Normal, count = 5882\n",
            "Component 1: Normal, count = 18630\n",
            "Component 2: Normal, count = 5488\n",
            "\n",
            "Iteration 35: Log-likelihood = -467.67980865367196\n",
            "Component 0: Normal, count = 5754\n",
            "Component 1: Normal, count = 18792\n",
            "Component 2: Normal, count = 5454\n",
            "\n",
            "Iteration 36: Log-likelihood = -467.63471184846196\n",
            "Component 0: Normal, count = 5696\n",
            "Component 1: Normal, count = 18844\n",
            "Component 2: Normal, count = 5460\n",
            "\n",
            "Iteration 37: Log-likelihood = -467.62941458533606\n",
            "Component 0: Normal, count = 5778\n",
            "Component 1: Normal, count = 18787\n",
            "Component 2: Normal, count = 5435\n",
            "\n",
            "Iteration 38: Log-likelihood = -467.6426315752711\n",
            "Component 0: Normal, count = 5757\n",
            "Component 1: Normal, count = 18804\n",
            "Component 2: Normal, count = 5439\n",
            "\n",
            "Iteration 39: Log-likelihood = -467.6469031724239\n",
            "Component 0: Normal, count = 5711\n",
            "Component 1: Normal, count = 18927\n",
            "Component 2: Normal, count = 5362\n",
            "\n",
            "Iteration 40: Log-likelihood = -467.6255571276951\n",
            "Component 0: Normal, count = 5675\n",
            "Component 1: Normal, count = 19022\n",
            "Component 2: Normal, count = 5303\n",
            "\n",
            "Iteration 41: Log-likelihood = -467.5959966738428\n",
            "Component 0: Normal, count = 5680\n",
            "Component 1: Normal, count = 19004\n",
            "Component 2: Normal, count = 5316\n",
            "\n",
            "Iteration 42: Log-likelihood = -467.5947502611591\n",
            "Component 0: Normal, count = 5764\n",
            "Component 1: Normal, count = 18965\n",
            "Component 2: Normal, count = 5271\n",
            "\n",
            "Iteration 43: Log-likelihood = -467.60310914784685\n",
            "Component 0: Normal, count = 5828\n",
            "Component 1: Normal, count = 18961\n",
            "Component 2: Normal, count = 5211\n",
            "\n",
            "Iteration 44: Log-likelihood = -467.60471830898064\n",
            "Component 0: Normal, count = 5654\n",
            "Component 1: Normal, count = 19095\n",
            "Component 2: Normal, count = 5251\n",
            "\n",
            "Iteration 45: Log-likelihood = -467.56312299340414\n",
            "Component 0: Normal, count = 5617\n",
            "Component 1: Normal, count = 19107\n",
            "Component 2: Normal, count = 5276\n",
            "\n",
            "Iteration 46: Log-likelihood = -467.57494055368295\n",
            "Component 0: Normal, count = 5571\n",
            "Component 1: Normal, count = 19272\n",
            "Component 2: Normal, count = 5157\n",
            "\n",
            "Iteration 47: Log-likelihood = -467.5354839599357\n",
            "Component 0: Normal, count = 5528\n",
            "Component 1: Normal, count = 19261\n",
            "Component 2: Normal, count = 5211\n",
            "\n",
            "Iteration 48: Log-likelihood = -467.559731720212\n",
            "Component 0: Normal, count = 5489\n",
            "Component 1: Normal, count = 19364\n",
            "Component 2: Normal, count = 5147\n",
            "\n",
            "Iteration 49: Log-likelihood = -467.54479351684284\n",
            "Component 0: Normal, count = 5493\n",
            "Component 1: Normal, count = 19387\n",
            "Component 2: Normal, count = 5120\n",
            "\n",
            "Iteration 50: Log-likelihood = -467.53522306906973\n",
            "Component 0: Normal, count = 5617\n",
            "Component 1: Normal, count = 19246\n",
            "Component 2: Normal, count = 5137\n",
            "\n",
            "Iteration 51: Log-likelihood = -467.60434466336653\n",
            "Component 0: Normal, count = 5613\n",
            "Component 1: Normal, count = 19228\n",
            "Component 2: Normal, count = 5159\n",
            "\n",
            "Iteration 52: Log-likelihood = -467.5690889166842\n",
            "Component 0: Normal, count = 5658\n",
            "Component 1: Normal, count = 19089\n",
            "Component 2: Normal, count = 5253\n",
            "\n",
            "Iteration 53: Log-likelihood = -467.5921833348275\n",
            "Component 0: Normal, count = 5683\n",
            "Component 1: Normal, count = 18993\n",
            "Component 2: Normal, count = 5324\n",
            "\n",
            "Iteration 54: Log-likelihood = -467.6022231085061\n",
            "Component 0: Normal, count = 5752\n",
            "Component 1: Normal, count = 18842\n",
            "Component 2: Normal, count = 5406\n",
            "\n",
            "Iteration 55: Log-likelihood = -467.644884921542\n",
            "Component 0: Normal, count = 5798\n",
            "Component 1: Normal, count = 18787\n",
            "Component 2: Normal, count = 5415\n",
            "\n",
            "Iteration 56: Log-likelihood = -467.64570788509906\n",
            "Component 0: Normal, count = 5830\n",
            "Component 1: Normal, count = 18781\n",
            "Component 2: Normal, count = 5389\n",
            "\n",
            "Iteration 57: Log-likelihood = -467.6448046317262\n",
            "Component 0: Normal, count = 5728\n",
            "Component 1: Normal, count = 18914\n",
            "Component 2: Normal, count = 5358\n",
            "\n",
            "Iteration 58: Log-likelihood = -467.6048539183368\n",
            "Component 0: Normal, count = 5668\n",
            "Component 1: Normal, count = 18973\n",
            "Component 2: Normal, count = 5359\n",
            "\n",
            "Iteration 59: Log-likelihood = -467.5920994531128\n",
            "Component 0: Normal, count = 5700\n",
            "Component 1: Normal, count = 18940\n",
            "Component 2: Normal, count = 5360\n",
            "\n",
            "Iteration 60: Log-likelihood = -467.60671795928596\n",
            "Component 0: Normal, count = 5625\n",
            "Component 1: Normal, count = 19063\n",
            "Component 2: Normal, count = 5312\n",
            "\n",
            "Iteration 61: Log-likelihood = -467.5723185237627\n",
            "Component 0: Normal, count = 5637\n",
            "Component 1: Normal, count = 19101\n",
            "Component 2: Normal, count = 5262\n",
            "\n",
            "Iteration 62: Log-likelihood = -467.55845324369795\n",
            "Component 0: Normal, count = 5639\n",
            "Component 1: Normal, count = 19142\n",
            "Component 2: Normal, count = 5219\n",
            "\n",
            "Iteration 63: Log-likelihood = -467.54689220691836\n",
            "Component 0: Normal, count = 5746\n",
            "Component 1: Normal, count = 19035\n",
            "Component 2: Normal, count = 5219\n",
            "\n",
            "Iteration 64: Log-likelihood = -467.57487207616606\n",
            "Component 0: Normal, count = 5603\n",
            "Component 1: Normal, count = 19194\n",
            "Component 2: Normal, count = 5203\n",
            "\n",
            "Iteration 65: Log-likelihood = -467.5332004589482\n",
            "Component 0: Normal, count = 5600\n",
            "Component 1: Normal, count = 19284\n",
            "Component 2: Normal, count = 5116\n",
            "\n",
            "Iteration 66: Log-likelihood = -467.5288949647349\n",
            "Component 0: Normal, count = 5587\n",
            "Component 1: Normal, count = 19289\n",
            "Component 2: Normal, count = 5124\n",
            "\n",
            "Iteration 67: Log-likelihood = -467.50977525680224\n",
            "Component 0: Normal, count = 5510\n",
            "Component 1: Normal, count = 19341\n",
            "Component 2: Normal, count = 5149\n",
            "\n",
            "Iteration 68: Log-likelihood = -467.5199722872161\n",
            "Component 0: Normal, count = 5573\n",
            "Component 1: Normal, count = 19264\n",
            "Component 2: Normal, count = 5163\n",
            "\n",
            "Iteration 69: Log-likelihood = -467.5378929395577\n",
            "Component 0: Normal, count = 5451\n",
            "Component 1: Normal, count = 19356\n",
            "Component 2: Normal, count = 5193\n",
            "\n",
            "Iteration 70: Log-likelihood = -467.50601056057627\n",
            "Component 0: Normal, count = 5396\n",
            "Component 1: Normal, count = 19342\n",
            "Component 2: Normal, count = 5262\n",
            "\n",
            "Iteration 71: Log-likelihood = -467.512970258409\n",
            "Component 0: Normal, count = 5421\n",
            "Component 1: Normal, count = 19308\n",
            "Component 2: Normal, count = 5271\n",
            "\n",
            "Iteration 72: Log-likelihood = -467.52741186283777\n",
            "Component 0: Normal, count = 5291\n",
            "Component 1: Normal, count = 19414\n",
            "Component 2: Normal, count = 5295\n",
            "\n",
            "Iteration 73: Log-likelihood = -467.5087683625956\n",
            "Component 0: Normal, count = 5376\n",
            "Component 1: Normal, count = 19347\n",
            "Component 2: Normal, count = 5277\n",
            "\n",
            "Iteration 74: Log-likelihood = -467.5175596370542\n",
            "Component 0: Normal, count = 5342\n",
            "Component 1: Normal, count = 19542\n",
            "Component 2: Normal, count = 5116\n",
            "\n",
            "Iteration 75: Log-likelihood = -467.5000656374599\n",
            "Component 0: Normal, count = 5271\n",
            "Component 1: Normal, count = 19646\n",
            "Component 2: Normal, count = 5083\n",
            "\n",
            "Iteration 76: Log-likelihood = -467.4636829730477\n",
            "Component 0: Normal, count = 5207\n",
            "Component 1: Normal, count = 19698\n",
            "Component 2: Normal, count = 5095\n",
            "\n",
            "Iteration 77: Log-likelihood = -467.4441084285576\n",
            "Component 0: Normal, count = 5126\n",
            "Component 1: Normal, count = 19760\n",
            "Component 2: Normal, count = 5114\n",
            "\n",
            "Iteration 78: Log-likelihood = -467.452782632304\n",
            "Component 0: Normal, count = 5121\n",
            "Component 1: Normal, count = 19761\n",
            "Component 2: Normal, count = 5118\n",
            "\n",
            "Iteration 79: Log-likelihood = -467.42786770018887\n",
            "Component 0: Normal, count = 5106\n",
            "Component 1: Normal, count = 19830\n",
            "Component 2: Normal, count = 5064\n",
            "\n",
            "Iteration 80: Log-likelihood = -467.4280826815085\n",
            "Component 0: Normal, count = 5158\n",
            "Component 1: Normal, count = 19733\n",
            "Component 2: Normal, count = 5109\n",
            "\n",
            "Iteration 81: Log-likelihood = -467.41998371817334\n",
            "Component 0: Normal, count = 5114\n",
            "Component 1: Normal, count = 19734\n",
            "Component 2: Normal, count = 5152\n",
            "\n",
            "Iteration 82: Log-likelihood = -467.41860830109385\n",
            "Component 0: Normal, count = 5033\n",
            "Component 1: Normal, count = 19770\n",
            "Component 2: Normal, count = 5197\n",
            "\n",
            "Iteration 83: Log-likelihood = -467.43320433785664\n",
            "Component 0: Normal, count = 5052\n",
            "Component 1: Normal, count = 19747\n",
            "Component 2: Normal, count = 5201\n",
            "\n",
            "Iteration 84: Log-likelihood = -467.45675944174974\n",
            "Component 0: Normal, count = 5081\n",
            "Component 1: Normal, count = 19728\n",
            "Component 2: Normal, count = 5191\n",
            "\n",
            "Iteration 85: Log-likelihood = -467.46048692122173\n",
            "Component 0: Normal, count = 5267\n",
            "Component 1: Normal, count = 19424\n",
            "Component 2: Normal, count = 5309\n",
            "\n",
            "Iteration 86: Log-likelihood = -467.5342370380658\n",
            "Component 0: Normal, count = 5286\n",
            "Component 1: Normal, count = 19375\n",
            "Component 2: Normal, count = 5339\n",
            "\n",
            "Iteration 87: Log-likelihood = -467.541767235289\n",
            "Component 0: Normal, count = 5259\n",
            "Component 1: Normal, count = 19285\n",
            "Component 2: Normal, count = 5456\n",
            "\n",
            "Iteration 88: Log-likelihood = -467.54819022088066\n",
            "Component 0: Normal, count = 5278\n",
            "Component 1: Normal, count = 19151\n",
            "Component 2: Normal, count = 5571\n",
            "\n",
            "Iteration 89: Log-likelihood = -467.5784601985328\n",
            "Component 0: Normal, count = 5324\n",
            "Component 1: Normal, count = 19106\n",
            "Component 2: Normal, count = 5570\n",
            "\n",
            "Iteration 90: Log-likelihood = -467.572407801799\n",
            "Component 0: Normal, count = 5249\n",
            "Component 1: Normal, count = 19234\n",
            "Component 2: Normal, count = 5517\n",
            "\n",
            "Iteration 91: Log-likelihood = -467.5697190793033\n",
            "Component 0: Normal, count = 5237\n",
            "Component 1: Normal, count = 19130\n",
            "Component 2: Normal, count = 5633\n",
            "\n",
            "Iteration 92: Log-likelihood = -467.583113934672\n",
            "Component 0: Normal, count = 5224\n",
            "Component 1: Normal, count = 19127\n",
            "Component 2: Normal, count = 5649\n",
            "\n",
            "Iteration 93: Log-likelihood = -467.5980727107616\n",
            "Component 0: Normal, count = 5293\n",
            "Component 1: Normal, count = 19102\n",
            "Component 2: Normal, count = 5605\n",
            "\n",
            "Iteration 94: Log-likelihood = -467.5863902475498\n",
            "Component 0: Normal, count = 5306\n",
            "Component 1: Normal, count = 19180\n",
            "Component 2: Normal, count = 5514\n",
            "\n",
            "Iteration 95: Log-likelihood = -467.54784221492804\n",
            "Component 0: Normal, count = 5167\n",
            "Component 1: Normal, count = 19299\n",
            "Component 2: Normal, count = 5534\n",
            "\n",
            "Iteration 96: Log-likelihood = -467.52156115480125\n",
            "Component 0: Normal, count = 5146\n",
            "Component 1: Normal, count = 19338\n",
            "Component 2: Normal, count = 5516\n",
            "\n",
            "Iteration 97: Log-likelihood = -467.5211544715051\n",
            "Component 0: Normal, count = 5175\n",
            "Component 1: Normal, count = 19344\n",
            "Component 2: Normal, count = 5481\n",
            "\n",
            "Iteration 98: Log-likelihood = -467.53569995930826\n",
            "Component 0: Normal, count = 5213\n",
            "Component 1: Normal, count = 19373\n",
            "Component 2: Normal, count = 5414\n",
            "\n",
            "Iteration 99: Log-likelihood = -467.5312930674716\n",
            "Component 0: Normal, count = 5163\n",
            "Component 1: Normal, count = 19505\n",
            "Component 2: Normal, count = 5332\n",
            "\n",
            "Iteration 100: Log-likelihood = -467.51112633230207\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final parameters:\n",
            "Component 1: Normal\n",
            "Parameters: 3.06140719486068 1.2051254631527415\n",
            "Weight: 0.17210000001612333\n",
            "\n",
            "Component 2: Normal\n",
            "Parameters: 1.4752597491207786 0.7941915261404384\n",
            "Weight: 0.6501666666349833\n",
            "\n",
            "Component 3: Normal\n",
            "Parameters: 2.818394639010778 1.279329463650946\n",
            "Weight: 0.17773333334889335\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a user input based code, where the user may pick the amount of mixes, distribution types, and parameters.\n",
        "\n",
        "I will focus on two functions implemented here:\n",
        "\n",
        "- e_step_MCMC: This step iterates between each data point, makes a list of our current weight mix times the pdf at data point value, sums it up to then on make probability weight for our initial z value. It then goes to iterate over the num steps we decided by look at a random z, checking it $\\alpha$, and making a random decision to go to that z, and add it to the list.\n",
        "\n",
        "- m_step_MCMC: This step flattens our list of lists (or changes seperate samples into one big sample). For each component, is counts the amount of sample points we got, and divides by total. Whats important here is the inclusion of the min_weight, which tells us that no matter what no mixed weight will be below 0.05. This can obviously cause problems for higher mixes, but if we didn't have some minimum value here we could possibly get a mixing weight of 0. This would in turn totally close off the distribution being a possibility for the next sample. This is normalized then after.\n"
      ],
      "metadata": {
        "id": "WKjGswtIuQmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The second I did was the normal..."
      ],
      "metadata": {
        "id": "pZ5hdw1tuEY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import functools\n",
        "\n",
        "#Normal#########################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "################################################################################\n",
        "def pick_distribution(answer):\n",
        "\n",
        "  if answer == \"Uniform\":\n",
        "    while True:\n",
        "      try:\n",
        "        a0 = float(input(\"Initial lower bound guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    while True:\n",
        "      try:\n",
        "        b0 = float(input(\"Initial upper bound guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x):\n",
        "      return 1 / (b0 - a0) if a0 <= x <= b0 else 0\n",
        "\n",
        "    return pdf, (a0, b0)\n",
        "\n",
        "  if answer == \"Exponential\":\n",
        "    while True:\n",
        "      try:\n",
        "        theta0 = float(input(\"Enter the mean guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    def pdf(x):\n",
        "      return (1 / theta0) * math.exp(-x / theta0) if x >= 0 else 0\n",
        "\n",
        "    return pdf, (theta0,) # Corrected parameter return\n",
        "\n",
        "  if answer == \"Normal\":\n",
        "    while True:\n",
        "      try:\n",
        "        mu0 = float(input(\"Enter the mean guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    while True:\n",
        "      try:\n",
        "        sigma0 = float(input(\"Enter the standard deviation guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x_val):\n",
        "      return (1 / (sigma0 * math.sqrt(2 * math.pi))) * math.exp(-(x_val - mu0)**2 / (2 * sigma0**2))\n",
        "    return pdf, (mu0, sigma0)\n",
        "\n",
        "  if answer == \"Bernoulli\":\n",
        "    while True:\n",
        "        try:\n",
        "            p = float(input(\"Enter probability of success (0 < p < 1): \"))\n",
        "            if 0 < p < 1:\n",
        "                break\n",
        "            else:\n",
        "                print(\"p must be between 0 and 1.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    def pdf(x):\n",
        "        return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "\n",
        "    return pdf, (p,)\n",
        "\n",
        "  if answer == \"Poisson\":\n",
        "\n",
        "    integer_data = [x for x in data if float(x).is_integer()]\n",
        "    estimated_lambda = np.mean(integer_data) if integer_data else 3.0\n",
        "\n",
        "    print(f\"Suggested lambda (from integer data): {estimated_lambda:.2f}\")\n",
        "    while True:\n",
        "        try:\n",
        "            lambda_val = float(input(\"Enter the Poisson mean (lambda): \"))\n",
        "            if lambda_val > 0:\n",
        "                break\n",
        "            else:\n",
        "                print(\"lambda must be greater than 0.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x):\n",
        "      if x >= 0 and float(x).is_integer():\n",
        "          return (math.exp(-lambda_val) * (lambda_val ** x)) / math.factorial(int(x)) # Corrected condition and factorial input\n",
        "      else:\n",
        "          return 0\n",
        "\n",
        "    return pdf, (lambda_val,)\n",
        "\n",
        "\n",
        "  # More distributions TBC\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "def e_step(data, components):\n",
        "  responsibilities = []\n",
        "  for x in data:\n",
        "    num = [comp[\"pi\"] * comp[\"pdf\"](x) for comp in components]\n",
        "    tot = sum(num)\n",
        "    if tot == 0:\n",
        "      probs = [1 / len(components)] * len(components)\n",
        "    else:\n",
        "      probs = [n / tot for n in num]\n",
        "    responsibilities.append(probs)\n",
        "  return responsibilities\n",
        "\n",
        "def m_step(data, responsibilities, components):\n",
        "    n = len(data)\n",
        "    k = len(components)\n",
        "\n",
        "    for i in range(k):\n",
        "        r_i = [resp[i] for resp in responsibilities]\n",
        "        total_r = sum(r_i)\n",
        "        components[i][\"pi\"] = total_r / n if total_r > 0 else 1e-6\n",
        "\n",
        "        spec_data = [x * r for x, r in zip(data, r_i)]\n",
        "\n",
        "        if components[i][\"distr name\"] == \"Uniform\":\n",
        "            # Weighted min/max\n",
        "            weights = np.array(r_i)\n",
        "            if np.sum(weights) > 0:\n",
        "                x_array = np.array(data)\n",
        "                components[i][\"params\"] = (np.min(x_array[weights > 0]), np.max(x_array[weights > 0]))\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "\n",
        "        elif components[i][\"distr name\"] == \"Exponential\":\n",
        "            if total_r > 0:\n",
        "                theta = sum(spec_data) / total_r\n",
        "                components[i][\"params\"] = (theta,)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "\n",
        "        elif components[i][\"distr name\"] == \"Normal\":\n",
        "            if total_r > 0:\n",
        "                mu = sum(spec_data) / total_r\n",
        "                var = sum(r * ((x - mu)**2) for x, r in zip(data, r_i)) / total_r\n",
        "                sigma = math.sqrt(var)\n",
        "                components[i][\"params\"] = (mu, sigma)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "\n",
        "        elif components[i][\"distr name\"] == \"Bernoulli\":\n",
        "            if total_r > 0:\n",
        "                p = sum(spec_data) / total_r\n",
        "                components[i][\"params\"] = (p,)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "\n",
        "        elif components[i][\"distr name\"] == \"Poisson\":\n",
        "            if total_r > 0:\n",
        "                lambda_ = sum(spec_data) / total_r\n",
        "                components[i][\"params\"] = (lambda_,)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "\n",
        "\n",
        "    update_pdfs(components)\n",
        "    return components\n",
        "\n",
        "def update_pdfs(components):\n",
        "    for comp in components:\n",
        "        name = comp[\"distr name\"]\n",
        "        params = comp[\"params\"]\n",
        "\n",
        "        if name == \"Normal\":\n",
        "            mu, sigma = params\n",
        "            def f(x, mu=mu, sigma=sigma):\n",
        "                return (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(-(x - mu)**2 / (2 * sigma**2))\n",
        "            comp[\"pdf\"] = f\n",
        "\n",
        "        elif name == \"Poisson\":\n",
        "            lamb = params[0]\n",
        "            def f(x, lamb=lamb):\n",
        "                if x >= 0 and float(x).is_integer():\n",
        "                    return (math.exp(-lamb) * (lamb ** x)) / math.factorial(int(x))\n",
        "                else:\n",
        "                    return 0\n",
        "            comp[\"pdf\"] = f\n",
        "\n",
        "        elif name == \"Exponential\":\n",
        "            theta = params[0]\n",
        "            def f(x, theta=theta):\n",
        "                return (1 / theta) * math.exp(-x / theta) if x >= 0 else 0\n",
        "            comp[\"pdf\"] = f\n",
        "\n",
        "        elif name == \"Uniform\":\n",
        "            a, b = params\n",
        "            def f(x, a=a, b=b):\n",
        "                return 1 / (b - a) if a <= x <= b else 0\n",
        "            comp[\"pdf\"] = f\n",
        "\n",
        "        elif name == \"Bernoulli\":\n",
        "            p = params[0]\n",
        "            def f(x, p=p):\n",
        "                return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "            comp[\"pdf\"] = f\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown distribution name: {name}\")\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "def update_params_pdfs(data, components, z_samples):\n",
        "  k = len(components)\n",
        "  n = len(data)\n",
        "\n",
        "  flat_x = [x for i, x in enumerate(data) for j in range(len(z_samples[i]))]\n",
        "  flat_z = [z for chain in z_samples for z in chain]\n",
        "\n",
        "  for i in range(len(components)):\n",
        "      print(f\"Component {i}: {components[i]['distr name']}, count = {flat_z.count(i)}\")\n",
        "\n",
        "  print()\n",
        "\n",
        "  for i in range(k):\n",
        "\n",
        "    spec_data  = [x for x, z in zip(flat_x, flat_z) if z == i] # filters data points into what distribution we think the data points are associated with\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Uniform\":\n",
        "      if spec_data: # Add check for empty list\n",
        "        components[i][\"params\"] = (min(spec_data), max(spec_data))\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Exponential\":\n",
        "      if spec_data: # Add check for empty list\n",
        "        components[i][\"params\"] = (np.mean(spec_data),)\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Normal\":\n",
        "      if spec_data: # Add check for empty list\n",
        "        components[i][\"params\"] = (np.mean(spec_data), np.std(spec_data))\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Bernoulli\":\n",
        "      if spec_data:\n",
        "        components[i][\"params\"] = (np.mean(spec_data),)\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Poisson\":\n",
        "      if spec_data:\n",
        "        components[i][\"params\"] = (np.mean(spec_data),)\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "  for comp in components:\n",
        "      name = comp[\"distr name\"]\n",
        "      params = comp[\"params\"]\n",
        "\n",
        "      if name == \"Normal\":\n",
        "        if len(spec_data) > 5:\n",
        "          mu, sigma = params\n",
        "          def f(x, mu=mu, sigma=sigma):\n",
        "              return (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(-(x - mu)**2 / (2 * sigma**2))\n",
        "          comp[\"pdf\"] = f\n",
        "      elif name == \"Poisson\":\n",
        "          lamb = params[0]\n",
        "          def f(x, lamb=lamb):\n",
        "              if x >= 0 and float(x).is_integer():\n",
        "                  return (math.exp(-lamb) * (lamb ** x)) / math.factorial(int(x))\n",
        "              else:\n",
        "                  return 0\n",
        "          comp[\"pdf\"] = f\n",
        "      elif name == \"Exponential\":\n",
        "          theta = params[0]\n",
        "          def f(x, theta=theta):\n",
        "              return (1 / theta) * math.exp(-x / theta) if x >= 0 else 0\n",
        "          comp[\"pdf\"] = f\n",
        "      elif name == \"Uniform\":\n",
        "          a, b = params\n",
        "          def f(x, a=a, b=b):\n",
        "              return 1 / (b - a) if a <= x <= b else 0\n",
        "          comp[\"pdf\"] = f\n",
        "      elif name == \"Bernoulli\":\n",
        "          p = params[0]\n",
        "          def f(x, p=p):\n",
        "              return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "          comp[\"pdf\"] = f\n",
        "      else:\n",
        "          raise ValueError(f\"Unknown distribution name: {name}\")\n",
        "\n",
        "  return components\n",
        "\n",
        "def compute_log_likelihood(data, components):\n",
        "    log_likelihood = 0\n",
        "    for x in data:\n",
        "        mixture_prob = sum(comp['pi'] * comp['pdf'](x) for comp in components)\n",
        "        if mixture_prob > 0:\n",
        "            log_likelihood += np.log(mixture_prob)\n",
        "    return log_likelihood\n",
        "\n",
        "\n",
        "def EM_MCMC(data, num_iters):\n",
        "\n",
        "  components = []\n",
        "\n",
        "  # data = [0, 1, 8, 6, 2, 4] # Removed hardcoded data\n",
        "\n",
        "  num_components = int(input(\"How many distributions would you like to mix? \"))\n",
        "\n",
        "  components = []\n",
        "  for i in range(num_components):\n",
        "    distr = ''\n",
        "    while distr not in [\"Uniform\", \"Exponential\", \"Normal\", \"Poisson\", \"Bernoulli\"]:\n",
        "      distr = input(f\"Choose distribution {i+1}: \")\n",
        "    pdf_f, param = pick_distribution(distr)\n",
        "    components.append({\"distr name\": distr, \"pdf\": pdf_f, \"params\": param, \"pi\": 1 / num_components}) # --> Start by assuming that each data point has equal\n",
        "                                                                                                          # chance of being associated with one of the distributions.\n",
        "  ll_list = []\n",
        "  for i in range(num_iters):\n",
        "    z_samples = e_step_MCMC(data, components) #\n",
        "    components = m_step_MCMC(z_samples, components)\n",
        "    components = update_params_pdfs(data, components, z_samples)\n",
        "\n",
        "    ll = compute_log_likelihood(data, components)\n",
        "    ll_list.append(ll)\n",
        "    if i > 0:\n",
        "      print(f\"Iteration {i+1}: Log-likelihood = {ll}\")\n",
        "\n",
        "  # plot log likelihood changes\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.scatter(range(len(ll_list)), ll_list, label='Data')\n",
        "\n",
        "  coeffs = np.polyfit(range(len(ll_list)), ll_list, deg=3)\n",
        "  trendline = np.poly1d(coeffs)\n",
        "\n",
        "  plt.plot(range(len(ll_list)), trendline(range(len(ll_list))), color='blue', label='Trendline')\n",
        "\n",
        "  plt.xlabel(\"iteration\")\n",
        "  plt.ylabel(\"log likelihood\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Final parameters:\")\n",
        "\n",
        "  for i in range(len(components)):\n",
        "    print(f\"Component {i+1}: {components[i]['distr name']}\")\n",
        "    print(\"Parameters:\", *(float(x) for x in components[i]['params']))\n",
        "    print(f\"Weight: {float(components[i]['pi'])}\")\n",
        "    print()\n",
        "  return\n",
        "\n",
        "np.random.seed(924)\n",
        "\n",
        "# Generate data\n",
        "n = 300\n",
        "data = []\n",
        "\n",
        "# 40% Normal(2, 0.5)\n",
        "data += list(np.random.normal(loc=2, scale=0.5, size=int(0.4 * n)))\n",
        "\n",
        "# 30% Uniform(0,5)\n",
        "data += list(np.random.uniform(0,5, size=int(0.3 * n)))\n",
        "\n",
        "# 30% Exponential(1.5)\n",
        "data += list(np.random.exponential(scale=1.5, size=int(0.3 * n)))\n",
        "\n",
        "# Optional: Shuffle the data\n",
        "random.shuffle(data)\n",
        "\n",
        "\n",
        "EM_MCMC(data, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F98FmMkluL10",
        "outputId": "5db80606-24c7-40ad-8ec1-23fba8dd0529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How many distributions would you like to mix? 3\n",
            "Choose distribution 1: Normal\n",
            "Enter the mean guess: 2\n",
            "Enter the standard deviation guess: 3\n",
            "Choose distribution 2: Normal\n",
            "Enter the mean guess: 3\n",
            "Enter the standard deviation guess: 5\n",
            "Choose distribution 3: Normal\n",
            "Enter the mean guess: 1\n",
            "Enter the standard deviation guess: \n",
            "Invalid input. Please enter a number.\n",
            "Enter the standard deviation guess: 3\n",
            "Component 0: Normal, count = 11740\n",
            "Component 1: Normal, count = 7231\n",
            "Component 2: Normal, count = 11029\n",
            "\n",
            "Component 0: Normal, count = 11755\n",
            "Component 1: Normal, count = 7163\n",
            "Component 2: Normal, count = 11082\n",
            "\n",
            "Iteration 2: Log-likelihood = -479.2101814885265\n",
            "Component 0: Normal, count = 11783\n",
            "Component 1: Normal, count = 7061\n",
            "Component 2: Normal, count = 11156\n",
            "\n",
            "Iteration 3: Log-likelihood = -478.00616366101605\n",
            "Component 0: Normal, count = 11780\n",
            "Component 1: Normal, count = 7026\n",
            "Component 2: Normal, count = 11194\n",
            "\n",
            "Iteration 4: Log-likelihood = -476.2400634771803\n",
            "Component 0: Normal, count = 11526\n",
            "Component 1: Normal, count = 7089\n",
            "Component 2: Normal, count = 11385\n",
            "\n",
            "Iteration 5: Log-likelihood = -474.2146771402184\n",
            "Component 0: Normal, count = 11373\n",
            "Component 1: Normal, count = 7177\n",
            "Component 2: Normal, count = 11450\n",
            "\n",
            "Iteration 6: Log-likelihood = -472.6527610460633\n",
            "Component 0: Normal, count = 11197\n",
            "Component 1: Normal, count = 7249\n",
            "Component 2: Normal, count = 11554\n",
            "\n",
            "Iteration 7: Log-likelihood = -471.23344410760535\n",
            "Component 0: Normal, count = 10983\n",
            "Component 1: Normal, count = 7251\n",
            "Component 2: Normal, count = 11766\n",
            "\n",
            "Iteration 8: Log-likelihood = -470.35236528767524\n",
            "Component 0: Normal, count = 10885\n",
            "Component 1: Normal, count = 7275\n",
            "Component 2: Normal, count = 11840\n",
            "\n",
            "Iteration 9: Log-likelihood = -469.85702557066423\n",
            "Component 0: Normal, count = 10677\n",
            "Component 1: Normal, count = 7370\n",
            "Component 2: Normal, count = 11953\n",
            "\n",
            "Iteration 10: Log-likelihood = -469.37054253105305\n",
            "Component 0: Normal, count = 10493\n",
            "Component 1: Normal, count = 7466\n",
            "Component 2: Normal, count = 12041\n",
            "\n",
            "Iteration 11: Log-likelihood = -468.99102987361493\n",
            "Component 0: Normal, count = 10555\n",
            "Component 1: Normal, count = 7421\n",
            "Component 2: Normal, count = 12024\n",
            "\n",
            "Iteration 12: Log-likelihood = -468.7287387552217\n",
            "Component 0: Normal, count = 10413\n",
            "Component 1: Normal, count = 7474\n",
            "Component 2: Normal, count = 12113\n",
            "\n",
            "Iteration 13: Log-likelihood = -468.45524077493815\n",
            "Component 0: Normal, count = 10214\n",
            "Component 1: Normal, count = 7584\n",
            "Component 2: Normal, count = 12202\n",
            "\n",
            "Iteration 14: Log-likelihood = -468.1860960474819\n",
            "Component 0: Normal, count = 10121\n",
            "Component 1: Normal, count = 7561\n",
            "Component 2: Normal, count = 12318\n",
            "\n",
            "Iteration 15: Log-likelihood = -468.04000308268536\n",
            "Component 0: Normal, count = 9973\n",
            "Component 1: Normal, count = 7567\n",
            "Component 2: Normal, count = 12460\n",
            "\n",
            "Iteration 16: Log-likelihood = -467.85887499924286\n",
            "Component 0: Normal, count = 9904\n",
            "Component 1: Normal, count = 7649\n",
            "Component 2: Normal, count = 12447\n",
            "\n",
            "Iteration 17: Log-likelihood = -467.74685813643265\n",
            "Component 0: Normal, count = 9865\n",
            "Component 1: Normal, count = 7624\n",
            "Component 2: Normal, count = 12511\n",
            "\n",
            "Iteration 18: Log-likelihood = -467.61884506491407\n",
            "Component 0: Normal, count = 9941\n",
            "Component 1: Normal, count = 7574\n",
            "Component 2: Normal, count = 12485\n",
            "\n",
            "Iteration 19: Log-likelihood = -467.5618963215067\n",
            "Component 0: Normal, count = 9892\n",
            "Component 1: Normal, count = 7506\n",
            "Component 2: Normal, count = 12602\n",
            "\n",
            "Iteration 20: Log-likelihood = -467.5117690172133\n",
            "Component 0: Normal, count = 9865\n",
            "Component 1: Normal, count = 7536\n",
            "Component 2: Normal, count = 12599\n",
            "\n",
            "Iteration 21: Log-likelihood = -467.2863348166494\n",
            "Component 0: Normal, count = 10010\n",
            "Component 1: Normal, count = 7436\n",
            "Component 2: Normal, count = 12554\n",
            "\n",
            "Iteration 22: Log-likelihood = -467.21647424876323\n",
            "Component 0: Normal, count = 10016\n",
            "Component 1: Normal, count = 7459\n",
            "Component 2: Normal, count = 12525\n",
            "\n",
            "Iteration 23: Log-likelihood = -467.1599466614972\n",
            "Component 0: Normal, count = 10074\n",
            "Component 1: Normal, count = 7384\n",
            "Component 2: Normal, count = 12542\n",
            "\n",
            "Iteration 24: Log-likelihood = -467.15322898949023\n",
            "Component 0: Normal, count = 10112\n",
            "Component 1: Normal, count = 7344\n",
            "Component 2: Normal, count = 12544\n",
            "\n",
            "Iteration 25: Log-likelihood = -467.17494304898463\n",
            "Component 0: Normal, count = 10113\n",
            "Component 1: Normal, count = 7274\n",
            "Component 2: Normal, count = 12613\n",
            "\n",
            "Iteration 26: Log-likelihood = -467.16034372387446\n",
            "Component 0: Normal, count = 9980\n",
            "Component 1: Normal, count = 7252\n",
            "Component 2: Normal, count = 12768\n",
            "\n",
            "Iteration 27: Log-likelihood = -467.1105082927957\n",
            "Component 0: Normal, count = 9906\n",
            "Component 1: Normal, count = 7205\n",
            "Component 2: Normal, count = 12889\n",
            "\n",
            "Iteration 28: Log-likelihood = -466.9642788195398\n",
            "Component 0: Normal, count = 10037\n",
            "Component 1: Normal, count = 7167\n",
            "Component 2: Normal, count = 12796\n",
            "\n",
            "Iteration 29: Log-likelihood = -466.91423188865525\n",
            "Component 0: Normal, count = 10040\n",
            "Component 1: Normal, count = 7098\n",
            "Component 2: Normal, count = 12862\n",
            "\n",
            "Iteration 30: Log-likelihood = -466.85255446375834\n",
            "Component 0: Normal, count = 10138\n",
            "Component 1: Normal, count = 7056\n",
            "Component 2: Normal, count = 12806\n",
            "\n",
            "Iteration 31: Log-likelihood = -466.83928247182433\n",
            "Component 0: Normal, count = 10194\n",
            "Component 1: Normal, count = 7047\n",
            "Component 2: Normal, count = 12759\n",
            "\n",
            "Iteration 32: Log-likelihood = -466.7749464617098\n",
            "Component 0: Normal, count = 10302\n",
            "Component 1: Normal, count = 6997\n",
            "Component 2: Normal, count = 12701\n",
            "\n",
            "Iteration 33: Log-likelihood = -466.750742006632\n",
            "Component 0: Normal, count = 10353\n",
            "Component 1: Normal, count = 6933\n",
            "Component 2: Normal, count = 12714\n",
            "\n",
            "Iteration 34: Log-likelihood = -466.70606861063885\n",
            "Component 0: Normal, count = 10284\n",
            "Component 1: Normal, count = 6925\n",
            "Component 2: Normal, count = 12791\n",
            "\n",
            "Iteration 35: Log-likelihood = -466.70136707465605\n",
            "Component 0: Normal, count = 10291\n",
            "Component 1: Normal, count = 6875\n",
            "Component 2: Normal, count = 12834\n",
            "\n",
            "Iteration 36: Log-likelihood = -466.68715298798196\n",
            "Component 0: Normal, count = 10213\n",
            "Component 1: Normal, count = 6783\n",
            "Component 2: Normal, count = 13004\n",
            "\n",
            "Iteration 37: Log-likelihood = -466.70641169079204\n",
            "Component 0: Normal, count = 10253\n",
            "Component 1: Normal, count = 6688\n",
            "Component 2: Normal, count = 13059\n",
            "\n",
            "Iteration 38: Log-likelihood = -466.6729980168415\n",
            "Component 0: Normal, count = 10332\n",
            "Component 1: Normal, count = 6643\n",
            "Component 2: Normal, count = 13025\n",
            "\n",
            "Iteration 39: Log-likelihood = -466.6394441757253\n",
            "Component 0: Normal, count = 10362\n",
            "Component 1: Normal, count = 6610\n",
            "Component 2: Normal, count = 13028\n",
            "\n",
            "Iteration 40: Log-likelihood = -466.6120657915265\n",
            "Component 0: Normal, count = 10383\n",
            "Component 1: Normal, count = 6534\n",
            "Component 2: Normal, count = 13083\n",
            "\n",
            "Iteration 41: Log-likelihood = -466.5812245946366\n",
            "Component 0: Normal, count = 10410\n",
            "Component 1: Normal, count = 6472\n",
            "Component 2: Normal, count = 13118\n",
            "\n",
            "Iteration 42: Log-likelihood = -466.52694842819636\n",
            "Component 0: Normal, count = 10490\n",
            "Component 1: Normal, count = 6394\n",
            "Component 2: Normal, count = 13116\n",
            "\n",
            "Iteration 43: Log-likelihood = -466.4954711560158\n",
            "Component 0: Normal, count = 10537\n",
            "Component 1: Normal, count = 6277\n",
            "Component 2: Normal, count = 13186\n",
            "\n",
            "Iteration 44: Log-likelihood = -466.46245380844215\n",
            "Component 0: Normal, count = 10558\n",
            "Component 1: Normal, count = 6243\n",
            "Component 2: Normal, count = 13199\n",
            "\n",
            "Iteration 45: Log-likelihood = -466.42927702564197\n",
            "Component 0: Normal, count = 10548\n",
            "Component 1: Normal, count = 6216\n",
            "Component 2: Normal, count = 13236\n",
            "\n",
            "Iteration 46: Log-likelihood = -466.4116362792001\n",
            "Component 0: Normal, count = 10675\n",
            "Component 1: Normal, count = 6121\n",
            "Component 2: Normal, count = 13204\n",
            "\n",
            "Iteration 47: Log-likelihood = -466.40010236249265\n",
            "Component 0: Normal, count = 10605\n",
            "Component 1: Normal, count = 6073\n",
            "Component 2: Normal, count = 13322\n",
            "\n",
            "Iteration 48: Log-likelihood = -466.36043992263507\n",
            "Component 0: Normal, count = 10667\n",
            "Component 1: Normal, count = 5968\n",
            "Component 2: Normal, count = 13365\n",
            "\n",
            "Iteration 49: Log-likelihood = -466.3694038684707\n",
            "Component 0: Normal, count = 10632\n",
            "Component 1: Normal, count = 5958\n",
            "Component 2: Normal, count = 13410\n",
            "\n",
            "Iteration 50: Log-likelihood = -466.3271465246627\n",
            "Component 0: Normal, count = 10717\n",
            "Component 1: Normal, count = 5844\n",
            "Component 2: Normal, count = 13439\n",
            "\n",
            "Iteration 51: Log-likelihood = -466.29668137298717\n",
            "Component 0: Normal, count = 10850\n",
            "Component 1: Normal, count = 5771\n",
            "Component 2: Normal, count = 13379\n",
            "\n",
            "Iteration 52: Log-likelihood = -466.2738749396972\n",
            "Component 0: Normal, count = 10876\n",
            "Component 1: Normal, count = 5666\n",
            "Component 2: Normal, count = 13458\n",
            "\n",
            "Iteration 53: Log-likelihood = -466.24605835226055\n",
            "Component 0: Normal, count = 10932\n",
            "Component 1: Normal, count = 5568\n",
            "Component 2: Normal, count = 13500\n",
            "\n",
            "Iteration 54: Log-likelihood = -466.20380386108815\n",
            "Component 0: Normal, count = 11114\n",
            "Component 1: Normal, count = 5443\n",
            "Component 2: Normal, count = 13443\n",
            "\n",
            "Iteration 55: Log-likelihood = -466.1938670953746\n",
            "Component 0: Normal, count = 11295\n",
            "Component 1: Normal, count = 5319\n",
            "Component 2: Normal, count = 13386\n",
            "\n",
            "Iteration 56: Log-likelihood = -466.0809317878491\n",
            "Component 0: Normal, count = 11464\n",
            "Component 1: Normal, count = 5288\n",
            "Component 2: Normal, count = 13248\n",
            "\n",
            "Iteration 57: Log-likelihood = -466.03196472978874\n",
            "Component 0: Normal, count = 11729\n",
            "Component 1: Normal, count = 5213\n",
            "Component 2: Normal, count = 13058\n",
            "\n",
            "Iteration 58: Log-likelihood = -466.0012297581561\n",
            "Component 0: Normal, count = 11741\n",
            "Component 1: Normal, count = 5153\n",
            "Component 2: Normal, count = 13106\n",
            "\n",
            "Iteration 59: Log-likelihood = -465.94461295177575\n",
            "Component 0: Normal, count = 11838\n",
            "Component 1: Normal, count = 5056\n",
            "Component 2: Normal, count = 13106\n",
            "\n",
            "Iteration 60: Log-likelihood = -465.88770130117337\n",
            "Component 0: Normal, count = 11819\n",
            "Component 1: Normal, count = 5016\n",
            "Component 2: Normal, count = 13165\n",
            "\n",
            "Iteration 61: Log-likelihood = -465.8699372715901\n",
            "Component 0: Normal, count = 11842\n",
            "Component 1: Normal, count = 4986\n",
            "Component 2: Normal, count = 13172\n",
            "\n",
            "Iteration 62: Log-likelihood = -465.84540810986886\n",
            "Component 0: Normal, count = 11819\n",
            "Component 1: Normal, count = 4938\n",
            "Component 2: Normal, count = 13243\n",
            "\n",
            "Iteration 63: Log-likelihood = -465.81872388451677\n",
            "Component 0: Normal, count = 11990\n",
            "Component 1: Normal, count = 4805\n",
            "Component 2: Normal, count = 13205\n",
            "\n",
            "Iteration 64: Log-likelihood = -465.71956183764286\n",
            "Component 0: Normal, count = 12029\n",
            "Component 1: Normal, count = 4714\n",
            "Component 2: Normal, count = 13257\n",
            "\n",
            "Iteration 65: Log-likelihood = -465.68056222965134\n",
            "Component 0: Normal, count = 12135\n",
            "Component 1: Normal, count = 4653\n",
            "Component 2: Normal, count = 13212\n",
            "\n",
            "Iteration 66: Log-likelihood = -465.63978729758645\n",
            "Component 0: Normal, count = 12035\n",
            "Component 1: Normal, count = 4646\n",
            "Component 2: Normal, count = 13319\n",
            "\n",
            "Iteration 67: Log-likelihood = -465.59993119673584\n",
            "Component 0: Normal, count = 12247\n",
            "Component 1: Normal, count = 4542\n",
            "Component 2: Normal, count = 13211\n",
            "\n",
            "Iteration 68: Log-likelihood = -465.536519593174\n",
            "Component 0: Normal, count = 12273\n",
            "Component 1: Normal, count = 4442\n",
            "Component 2: Normal, count = 13285\n",
            "\n",
            "Iteration 69: Log-likelihood = -465.52348307030474\n",
            "Component 0: Normal, count = 12246\n",
            "Component 1: Normal, count = 4466\n",
            "Component 2: Normal, count = 13288\n",
            "\n",
            "Iteration 70: Log-likelihood = -465.4882253038559\n",
            "Component 0: Normal, count = 12288\n",
            "Component 1: Normal, count = 4392\n",
            "Component 2: Normal, count = 13320\n",
            "\n",
            "Iteration 71: Log-likelihood = -465.44175275198575\n",
            "Component 0: Normal, count = 12154\n",
            "Component 1: Normal, count = 4329\n",
            "Component 2: Normal, count = 13517\n",
            "\n",
            "Iteration 72: Log-likelihood = -465.41709903143385\n",
            "Component 0: Normal, count = 12147\n",
            "Component 1: Normal, count = 4282\n",
            "Component 2: Normal, count = 13571\n",
            "\n",
            "Iteration 73: Log-likelihood = -465.3640305901084\n",
            "Component 0: Normal, count = 12237\n",
            "Component 1: Normal, count = 4263\n",
            "Component 2: Normal, count = 13500\n",
            "\n",
            "Iteration 74: Log-likelihood = -465.325548472609\n",
            "Component 0: Normal, count = 12363\n",
            "Component 1: Normal, count = 4165\n",
            "Component 2: Normal, count = 13472\n",
            "\n",
            "Iteration 75: Log-likelihood = -465.2960752253941\n",
            "Component 0: Normal, count = 12451\n",
            "Component 1: Normal, count = 4128\n",
            "Component 2: Normal, count = 13421\n",
            "\n",
            "Iteration 76: Log-likelihood = -465.2551903023565\n",
            "Component 0: Normal, count = 12502\n",
            "Component 1: Normal, count = 4041\n",
            "Component 2: Normal, count = 13457\n",
            "\n",
            "Iteration 77: Log-likelihood = -465.20299242189463\n",
            "Component 0: Normal, count = 12446\n",
            "Component 1: Normal, count = 4022\n",
            "Component 2: Normal, count = 13532\n",
            "\n",
            "Iteration 78: Log-likelihood = -465.1692834542562\n",
            "Component 0: Normal, count = 12511\n",
            "Component 1: Normal, count = 3947\n",
            "Component 2: Normal, count = 13542\n",
            "\n",
            "Iteration 79: Log-likelihood = -465.13743752607405\n",
            "Component 0: Normal, count = 12630\n",
            "Component 1: Normal, count = 3904\n",
            "Component 2: Normal, count = 13466\n",
            "\n",
            "Iteration 80: Log-likelihood = -465.13489550143345\n",
            "Component 0: Normal, count = 12567\n",
            "Component 1: Normal, count = 3878\n",
            "Component 2: Normal, count = 13555\n",
            "\n",
            "Iteration 81: Log-likelihood = -465.11778093958446\n",
            "Component 0: Normal, count = 12560\n",
            "Component 1: Normal, count = 3742\n",
            "Component 2: Normal, count = 13698\n",
            "\n",
            "Iteration 82: Log-likelihood = -465.07453000319543\n",
            "Component 0: Normal, count = 12497\n",
            "Component 1: Normal, count = 3749\n",
            "Component 2: Normal, count = 13754\n",
            "\n",
            "Iteration 83: Log-likelihood = -465.0595273533456\n",
            "Component 0: Normal, count = 12539\n",
            "Component 1: Normal, count = 3737\n",
            "Component 2: Normal, count = 13724\n",
            "\n",
            "Iteration 84: Log-likelihood = -465.06123259294924\n",
            "Component 0: Normal, count = 12683\n",
            "Component 1: Normal, count = 3670\n",
            "Component 2: Normal, count = 13647\n",
            "\n",
            "Iteration 85: Log-likelihood = -465.0575521319159\n",
            "Component 0: Normal, count = 12617\n",
            "Component 1: Normal, count = 3648\n",
            "Component 2: Normal, count = 13735\n",
            "\n",
            "Iteration 86: Log-likelihood = -465.05309421276\n",
            "Component 0: Normal, count = 12660\n",
            "Component 1: Normal, count = 3599\n",
            "Component 2: Normal, count = 13741\n",
            "\n",
            "Iteration 87: Log-likelihood = -465.03424272461876\n",
            "Component 0: Normal, count = 12633\n",
            "Component 1: Normal, count = 3637\n",
            "Component 2: Normal, count = 13730\n",
            "\n",
            "Iteration 88: Log-likelihood = -465.02340833021765\n",
            "Component 0: Normal, count = 12703\n",
            "Component 1: Normal, count = 3607\n",
            "Component 2: Normal, count = 13690\n",
            "\n",
            "Iteration 89: Log-likelihood = -465.0221249437375\n",
            "Component 0: Normal, count = 12735\n",
            "Component 1: Normal, count = 3576\n",
            "Component 2: Normal, count = 13689\n",
            "\n",
            "Iteration 90: Log-likelihood = -465.0118148057921\n",
            "Component 0: Normal, count = 12709\n",
            "Component 1: Normal, count = 3547\n",
            "Component 2: Normal, count = 13744\n",
            "\n",
            "Iteration 91: Log-likelihood = -465.00087825294435\n",
            "Component 0: Normal, count = 12672\n",
            "Component 1: Normal, count = 3564\n",
            "Component 2: Normal, count = 13764\n",
            "\n",
            "Iteration 92: Log-likelihood = -465.00723786833413\n",
            "Component 0: Normal, count = 12777\n",
            "Component 1: Normal, count = 3503\n",
            "Component 2: Normal, count = 13720\n",
            "\n",
            "Iteration 93: Log-likelihood = -465.01572834853624\n",
            "Component 0: Normal, count = 12820\n",
            "Component 1: Normal, count = 3470\n",
            "Component 2: Normal, count = 13710\n",
            "\n",
            "Iteration 94: Log-likelihood = -464.99362516523087\n",
            "Component 0: Normal, count = 12673\n",
            "Component 1: Normal, count = 3517\n",
            "Component 2: Normal, count = 13810\n",
            "\n",
            "Iteration 95: Log-likelihood = -464.98868692912146\n",
            "Component 0: Normal, count = 12655\n",
            "Component 1: Normal, count = 3456\n",
            "Component 2: Normal, count = 13889\n",
            "\n",
            "Iteration 96: Log-likelihood = -464.9881882882825\n",
            "Component 0: Normal, count = 12503\n",
            "Component 1: Normal, count = 3445\n",
            "Component 2: Normal, count = 14052\n",
            "\n",
            "Iteration 97: Log-likelihood = -464.96941455677927\n",
            "Component 0: Normal, count = 12696\n",
            "Component 1: Normal, count = 3437\n",
            "Component 2: Normal, count = 13867\n",
            "\n",
            "Iteration 98: Log-likelihood = -464.96612214648184\n",
            "Component 0: Normal, count = 12675\n",
            "Component 1: Normal, count = 3374\n",
            "Component 2: Normal, count = 13951\n",
            "\n",
            "Iteration 99: Log-likelihood = -464.9812312734092\n",
            "Component 0: Normal, count = 12734\n",
            "Component 1: Normal, count = 3436\n",
            "Component 2: Normal, count = 13830\n",
            "\n",
            "Iteration 100: Log-likelihood = -464.955771900302\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final parameters:\n",
            "Component 1: Normal\n",
            "Parameters: 1.949378465395374 0.9078222576650615\n",
            "Weight: 0.42446666665755334\n",
            "\n",
            "Component 2: Normal\n",
            "Parameters: 4.269695114192711 0.6182401989632673\n",
            "Weight: 0.11453333335521332\n",
            "\n",
            "Component 3: Normal\n",
            "Parameters: 1.454418595673254 0.8343874902808952\n",
            "Weight: 0.46099999998723334\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code goes off of how the Normal EM is a simple plug and chug method (which also makes it easier on the computer).\n",
        "\n",
        "I will analyze two functions again:\n",
        "\n",
        "- e_step: This creates us a list of responsibilities, where each row corresponds to a data point and each column is a distribution.\n",
        "\n",
        "- m_step: Updates by using the forumla which is the average of responsibilities for all data points. Also updates the parameters makes a utilizes the update_pdfs function which the MCMC EM didn't do."
      ],
      "metadata": {
        "id": "xuf45kye1Rv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After implementing, we now analyze certain data set that we already know the mixes, distributions, and parameters to. This dataset is is 40% normal, 30%  uniform and 30% Exponential. This gave us\n",
        "\n",
        "\n",
        "\n",
        "Normal EM:\n",
        "\n",
        "Final parameters:\n",
        "--Component 1: Normal\n",
        "--Parameters: 1.8423191947752293 0.5628494357388811\n",
        "--Weight: 0.4654666666534534\n",
        "\n",
        "--Component 2: Uniform\n",
        "--Parameters: 2.001249637992631 4.939563309234937\n",
        "--Weight: 0.20136666667986333\n",
        "\n",
        "--Component 3: Exponential\n",
        "--Parameters: 1.2616382356757725\n",
        "--Weight: 0.3331666666666833\n",
        "\n",
        "EMMC:\n",
        "\n",
        "Final parameters:\n",
        "--Component 1: Normal\n",
        "--Parameters: 1.8460064463447392 0.5583405533495043\n",
        "--Weight: 0.46846666665315334\n",
        "\n",
        "--Component 2: Uniform\n",
        "--Parameters: 2.001249637992631 4.939563309234937\n",
        "--Weight: 0.20186666667981334\n",
        "\n",
        "--Component 3: Exponential\n",
        "--Parameters: 1.2533636181134291\n",
        "--Weight: 0.3296666666670333"
      ],
      "metadata": {
        "id": "XTd-buam5iPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These values seem to be very closely related, showing that these 2 strategies are almost equivalent\n",
        "\n",
        "I tested with a mix of Continuous and Discrete distributions as well, and a common theme of it was that the continuous distributions dominated. I think this is possibly due to the fact that continuous distributions can take on values that discrete can, but the inverse is not true."
      ],
      "metadata": {
        "id": "Db8AYqWjDksO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To further my investigation, I created a mixing function which aloowed to create random mixes of different distributions. This code allowed to no user input and purely off computer randomness."
      ],
      "metadata": {
        "id": "EMaksPa4DuPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "from itertools import permutations\n",
        "\n",
        "#---------------- Distribution Picker ----------------#\n",
        "def pick_distribution(answer):\n",
        "    \"\"\"\n",
        "    Automatically assigns parameters and returns (pdf, param_tuple)\n",
        "    based on the chosen distribution name.\n",
        "    \"\"\"\n",
        "\n",
        "    if answer == \"Uniform\":\n",
        "        a0 = random.randint(0, 5)\n",
        "        b0 = random.randint(a0 + 1, a0 + 8)  # ensure b > a\n",
        "        def pdf(x): return 1 / (b0 - a0) if a0 <= x <= b0 else 0\n",
        "        return pdf, (a0, b0)\n",
        "\n",
        "    if answer == \"Exponential\":\n",
        "        theta0 = random.uniform(0.5, 5.0)\n",
        "        def pdf(x): return (1 / theta0) * math.exp(-x / theta0) if x >= 0 else 0\n",
        "        return pdf, (theta0,)\n",
        "\n",
        "    if answer == \"Normal\":\n",
        "        mu0 = random.uniform(-5, 5)\n",
        "        sigma0 = random.uniform(0.5, 3.0)\n",
        "        def pdf(x): return (1 / (sigma0 * math.sqrt(2 * math.pi))) * math.exp(-(x - mu0)**2 / (2 * sigma0**2))\n",
        "        return pdf, (mu0, sigma0)\n",
        "\n",
        "    if answer == \"Poisson\":\n",
        "        lambda_val = random.uniform(1, 8)\n",
        "        def pdf(x):\n",
        "            if x >= 0 and float(x).is_integer():\n",
        "                x_int = int(x)\n",
        "                # Add epsilon to lambda_val to prevent math.log(0)\n",
        "                log_pdf = -lambda_val + x_int * math.log(lambda_val + 1e-12) - math.lgamma(x_int + 1)\n",
        "                return math.exp(log_pdf)\n",
        "            return 0\n",
        "        return pdf, (lambda_val,)\n",
        "\n",
        "    if answer == \"Bernoulli\":\n",
        "        p = random.uniform(0.1, 0.9)\n",
        "        def pdf(x):\n",
        "            # Add epsilon to p and (1-p) to prevent math.log(0)\n",
        "            if x == 1: return p if p > 0 else 1e-12\n",
        "            elif x == 0: return (1 - p) if (1 - p) > 0 else 1e-12\n",
        "            else: return 0\n",
        "        return pdf, (p,)\n",
        "\n",
        "    raise ValueError(f\"Unsupported distribution name: {answer}\")\n",
        "\n",
        "#########################################EM Normal###############################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "\n",
        "#---------------- PDF Updater ----------------#\n",
        "def update_pdfs(components):\n",
        "    \"\"\"\n",
        "    After parameter updates, refresh each component's PDF.\n",
        "    \"\"\"\n",
        "    for comp in components:\n",
        "        name = comp[\"distr name\"]\n",
        "        params = comp[\"params\"]\n",
        "\n",
        "        if name == \"Normal\":\n",
        "            mu, sigma = params\n",
        "            # Add epsilon to sigma to prevent division by zero\n",
        "            comp[\"pdf\"] = lambda x, mu=mu, sigma=sigma: (1 / (sigma + 1e-12 * math.sqrt(2 * math.pi))) * math.exp(-(x - mu)**2 / (2 * (sigma + 1e-12)**2))\n",
        "\n",
        "        elif name == \"Poisson\":\n",
        "            lamb = params[0]\n",
        "            # Add epsilon to lamb to prevent math.log(0)\n",
        "            comp[\"pdf\"] = lambda x, lamb=lamb: math.exp(-lamb + x * math.log(lamb + 1e-12) - math.lgamma(x + 1)) if x >= 0 and float(x).is_integer() else 0\n",
        "\n",
        "        elif name == \"Exponential\":\n",
        "            theta = params[0]\n",
        "            # Add epsilon to theta to prevent division by zero\n",
        "            comp[\"pdf\"] = lambda x, theta=theta: (1 / (theta + 1e-12)) * math.exp(-x / (theta + 1e-12)) if x >= 0 else 0\n",
        "\n",
        "        elif name == \"Uniform\":\n",
        "            a, b = params\n",
        "            # Add epsilon to (b-a) to prevent division by zero\n",
        "            comp[\"pdf\"] = lambda x, a=a, b=b: 1 / (b - a + 1e-12) if a <= x <= b else 0\n",
        "\n",
        "        elif name == \"Bernoulli\":\n",
        "            p = params[0]\n",
        "            # Add epsilon to p and (1-p) to prevent math.log(0)\n",
        "            comp[\"pdf\"] = lambda x, p=p: p if x == 1 else (1 - p) if x == 0 else 0\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown distribution name: {name}\")\n",
        "\n",
        "#---------------- E-step ----------------#\n",
        "def e_step(data, components):\n",
        "    \"\"\"\n",
        "    Estimate responsibilities: P(z_i = j | x_i, θ)\n",
        "    \"\"\"\n",
        "    responsibilities = []\n",
        "    for x in data:\n",
        "        weighted_probs = [comp[\"pi\"] * comp[\"pdf\"](x) for comp in components]\n",
        "        total = sum(weighted_probs)\n",
        "        # Add epsilon to total to prevent division by zero or near zero\n",
        "        probs = [wp / (total + 1e-12) for wp in weighted_probs] if total > 0 else [1 / len(components)] * len(components)\n",
        "        responsibilities.append(probs)\n",
        "    return responsibilities\n",
        "\n",
        "#---------------- M-step ----------------#\n",
        "def m_step(data, responsibilities, components):\n",
        "    \"\"\"\n",
        "    Update weights and distribution parameters based on responsibilities.\n",
        "    \"\"\"\n",
        "    n = len(data)\n",
        "    k = len(components)\n",
        "\n",
        "    for i in range(k):\n",
        "        r_i = [resp[i] for resp in responsibilities]\n",
        "        total_r = sum(r_i)\n",
        "        # Add epsilon to n to prevent division by zero or near zero\n",
        "        components[i][\"pi\"] = total_r / (n + 1e-12) if total_r > 0 else 1e-12\n",
        "\n",
        "        weighted_data = [x * r for x, r in zip(data, r_i)]\n",
        "\n",
        "        name = components[i][\"distr name\"]\n",
        "\n",
        "        if name == \"Uniform\":\n",
        "            if np.sum(r_i) > 0:\n",
        "                x_array = np.array(data)\n",
        "                components[i][\"params\"] = (np.min(x_array), np.max(x_array))\n",
        "\n",
        "        elif name == \"Exponential\" and total_r > 0:\n",
        "            # Add epsilon to total_r to prevent division by zero or near zero\n",
        "            theta = sum(weighted_data) / (total_r + 1e-12)\n",
        "            components[i][\"params\"] = (max(theta, 1e-6),)\n",
        "\n",
        "        elif name == \"Normal\" and total_r > 0:\n",
        "            mu = sum(weighted_data) / (total_r + 1e-12)\n",
        "            var = sum(r * ((x - mu)**2) for x, r in zip(data, r_i)) / (total_r + 1e-12)\n",
        "            sigma = math.sqrt(max(var, 1e-12))\n",
        "            components[i][\"params\"] = (mu, sigma)\n",
        "\n",
        "        elif name == \"Bernoulli\" and total_r > 0:\n",
        "            p = sum(weighted_data) / max(total_r, 1e-12)\n",
        "            components[i][\"params\"] = (min(max(p, 1e-6), 1 - 1e-6),)\n",
        "\n",
        "        elif name == \"Poisson\" and total_r > 0:\n",
        "            lambda_ = sum(weighted_data) / max(total_r, 1e-12)\n",
        "            components[i][\"params\"] = (max(lambda_, 1e-6),)\n",
        "    update_pdfs(components)\n",
        "    return components\n",
        "#########################################EM MC###############################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "\n",
        "#---------------- E-Step (MCMC) ----------------#\n",
        "def e_step_MCMC(data, components, steps=300):\n",
        "    z_samples = []\n",
        "    k = len(components)\n",
        "    for x in data:\n",
        "        weighted_probs = [comp[\"pi\"] * comp[\"pdf\"](x) for comp in components]\n",
        "        total = sum(weighted_probs)\n",
        "        # Add epsilon to total to prevent division by zero or near zero\n",
        "        weights = [w / (total + 1e-12) for w in weighted_probs] if total > 0 else [1 / k] * k\n",
        "\n",
        "        # Explicitly re-normalize weights to sum to 1\n",
        "        weights_sum = sum(weights)\n",
        "        if weights_sum > 0:\n",
        "            weights = [w / weights_sum for w in weights]\n",
        "        else:\n",
        "            weights = [1 / k] * k # Fallback to equal weights if sum is zero\n",
        "\n",
        "        z = np.random.choice(range(k), p=weights)\n",
        "        chain = []\n",
        "        for _ in range(steps):\n",
        "            if k > 1:\n",
        "                z_new = np.random.choice([j for j in range(k) if j != z])\n",
        "                if components[z_new][\"distr name\"] in {\"Poisson\", \"Bernoulli\", \"Binomial\"} and not float(x).is_integer():\n",
        "                    chain.append(z)\n",
        "                    continue\n",
        "                num = components[z_new][\"pi\"] * components[z_new][\"pdf\"](x)\n",
        "                den = components[z][\"pi\"] * components[z][\"pdf\"](x)\n",
        "                # Add epsilon to den to prevent division by zero or near zero\n",
        "                alpha = min(1, num / (den + 1e-12) if den > 0 else 1)\n",
        "                if np.random.rand() < alpha:\n",
        "                    z = z_new\n",
        "            chain.append(z)\n",
        "        z_samples.append(chain)\n",
        "    return z_samples\n",
        "\n",
        "\n",
        "#---------------- M-Step ----------------#\n",
        "def m_step_MCMC(z_samples, components):\n",
        "    flatz = [z for chain in z_samples for z in chain]\n",
        "    total = len(flatz)\n",
        "    eps = 1e-6\n",
        "    min_weight = 0.05\n",
        "    for i in range(len(components)):\n",
        "        count_i = flatz.count(i)\n",
        "        # Add epsilon to total to prevent division by zero or near zero\n",
        "        pi_i = (count_i + eps) / (total + 1e-12)\n",
        "        components[i][\"pi\"] = max(min_weight, pi_i)\n",
        "    total_pi = sum(comp[\"pi\"] for comp in components)\n",
        "    # Add epsilon to total_pi to prevent division by zero or near zero\n",
        "    for comp in components:\n",
        "        comp[\"pi\"] /= (total_pi + 1e-12)\n",
        "    return components\n",
        "\n",
        "\n",
        "#---------------- Update Parameters ----------------#\n",
        "def update_params_pdfs(data, components, z_samples):\n",
        "    flat_x = [x for i, x in enumerate(data) for _ in z_samples[i]]\n",
        "    flat_z = [z for chain in z_samples for z in chain]\n",
        "    for i, comp in enumerate(components):\n",
        "        spec_data = [x for x, z in zip(flat_x, flat_z) if z == i]\n",
        "        if not spec_data:\n",
        "            continue\n",
        "        name = comp[\"distr name\"]\n",
        "        if name == \"Uniform\":\n",
        "            comp[\"params\"] = (min(spec_data), max(spec_data))\n",
        "        elif name == \"Exponential\":\n",
        "            comp[\"params\"] = (np.mean(spec_data),)\n",
        "        elif name == \"Normal\":\n",
        "            # Add epsilon to np.std to prevent zero standard deviation\n",
        "            comp[\"params\"] = (np.mean(spec_data), np.std(spec_data) + 1e-12)\n",
        "        elif name == \"Bernoulli\":\n",
        "            comp[\"params\"] = (np.mean(spec_data),)\n",
        "        elif name == \"Poisson\":\n",
        "            comp[\"params\"] = (np.mean(spec_data),)\n",
        "\n",
        "        # Update pdfs\n",
        "        params = comp[\"params\"]\n",
        "        if name == \"Normal\":\n",
        "            mu, sigma = params\n",
        "            # Add epsilon to sigma to prevent division by zero\n",
        "            comp[\"pdf\"] = lambda x, mu=mu, sigma=sigma: (1 / (sigma + 1e-12 * math.sqrt(2 * math.pi))) * math.exp(-(x - mu)**2 / (2 * (sigma + 1e-12)**2))\n",
        "        elif name == \"Poisson\":\n",
        "            lamb = params[0]\n",
        "            # Add epsilon to lamb to prevent math.log(0)\n",
        "            comp[\"pdf\"] = lambda x, lamb=lamb: math.exp(-lamb + x * math.log(lamb + 1e-12) - math.lgamma(x + 1)) if x >= 0 and float(x).is_integer() else 0\n",
        "        elif name == \"Exponential\":\n",
        "            theta = params[0]\n",
        "            # Add epsilon to theta to prevent division by zero\n",
        "            comp[\"pdf\"] = lambda x, theta=theta: (1 / (theta + 1e-12)) * math.exp(-x / (theta + 1e-12)) if x >= 0 else 0\n",
        "        elif name == \"Uniform\":\n",
        "            a, b = params\n",
        "            # Add epsilon to (b-a) to prevent division by zero\n",
        "            comp[\"pdf\"] = lambda x, a=a, b=b: 1 / (b - a + 1e-12) if a <= x <= b else 0\n",
        "        elif name == \"Bernoulli\":\n",
        "            p = params[0]\n",
        "            # Add epsilon to p and (1-p) to prevent math.log(0)\n",
        "            comp[\"pdf\"] = lambda x, p=p: p if x == 1 else (1 - p) if x == 0 else 0\n",
        "    return components\n",
        "\n",
        "#---------------- EM-MCMC Main ----------------#\n",
        "def EM_MCMC(data, true_comps, iter = 25):\n",
        "\n",
        "    complen = len(true_comps)\n",
        "    components = []\n",
        "    for i in range(complen):\n",
        "      distr = true_comps[i][\"distr name\"]\n",
        "      pdf_f, param = pick_distribution(distr)\n",
        "      components.append({\n",
        "          \"distr name\": distr,\n",
        "          \"pdf\": pdf_f,\n",
        "          \"params\": param,\n",
        "          \"pi\": 1/complen # we assume dont know the exact mix of the data\n",
        "      })\n",
        "\n",
        "    for i in range(iter):\n",
        "        z_samples = e_step_MCMC(data, components)\n",
        "        components = m_step_MCMC(z_samples, components)\n",
        "        components = update_params_pdfs(data, components, z_samples)\n",
        "\n",
        "    return [components[i]['pi'] for i in range(complen)]\n",
        "\n",
        "#---------------- EM Main ----------------#\n",
        "def EM(data, true_comps, iter = 25):\n",
        "\n",
        "    num_components = len(true_comps)\n",
        "    components = []\n",
        "    for i in range(num_components):\n",
        "        distr = true_comps[i][\"distr name\"]\n",
        "        pdf_f, param = pick_distribution(distr)\n",
        "        components.append({\n",
        "            \"distr name\": distr,\n",
        "            \"pdf\": pdf_f,\n",
        "            \"params\": param,\n",
        "            \"pi\": 1 / num_components\n",
        "        })\n",
        "\n",
        "    for i in range(iter):\n",
        "        responsibilities = e_step(data, components)\n",
        "        components = m_step(data, responsibilities, components)\n",
        "\n",
        "    return [components[i]['pi'] for i in range(num_components)]\n",
        "\n",
        "\n",
        "\n",
        "import random as rd\n",
        "\n",
        "\n",
        "def give_data_with_mixes_distribs_continuous():\n",
        "\n",
        "  num_mixes = rd.randint(2, 8)\n",
        "\n",
        "  distributions = [\"Uniform\", \"Exponential\", \"Normal\"]\n",
        "  components = []\n",
        "\n",
        "  true_components = []\n",
        "  sum = 0\n",
        "  for i in range(num_mixes):\n",
        "        distr = rd.choice(distributions)\n",
        "        pdf_f, param = pick_distribution(distr)\n",
        "        pi_i = rd.uniform(0, 1 - sum)\n",
        "        sum += pi_i\n",
        "        true_components.append({\n",
        "            \"distr name\": distr,\n",
        "            \"pdf\": pdf_f,\n",
        "            \"params\": param,\n",
        "            \"pi\": pi_i\n",
        "        })\n",
        "  # create data\n",
        "  data = []\n",
        "  n = rd.randint(5, 1000)\n",
        "  for comp in true_components:\n",
        "    if comp[\"distr name\"] == \"Uniform\":\n",
        "      data += list(np.random.uniform(comp[\"params\"][0], comp[\"params\"][1], size=int(comp[\"pi\"] * n)))\n",
        "    if comp[\"distr name\"] == \"Exponential\":\n",
        "      data += list(np.random.exponential(comp[\"params\"][0], size=int(comp[\"pi\"] * n)))\n",
        "    if comp[\"distr name\"] == \"Normal\":\n",
        "      data += list(np.random.normal(comp[\"params\"][0], comp[\"params\"][1], size=int(comp[\"pi\"] * n)))\n",
        "  return data, true_components\n",
        "  ############################################\n",
        "\n",
        "def give_data_with_mixes_distribs_discrete():\n",
        "\n",
        "  num_mixes = rd.randint(2, 8)\n",
        "\n",
        "  distributions = [\"Poisson\", \"Bernoulli\"]\n",
        "  components = []\n",
        "\n",
        "  true_components = []\n",
        "  sum = 0\n",
        "  for i in range(num_mixes):\n",
        "        distr = rd.choice(distributions)\n",
        "        pdf_f, param = pick_distribution(distr)\n",
        "        pi_i = rd.uniform(0, 1 - sum)\n",
        "        sum += pi_i\n",
        "        true_components.append({\n",
        "            \"distr name\": distr,\n",
        "            \"pdf\": pdf_f,\n",
        "            \"params\": param,\n",
        "            \"pi\": pi_i\n",
        "        })\n",
        "  # create data\n",
        "  data = []\n",
        "  n = rd.randint(5, 1000)\n",
        "  for comp in true_components:\n",
        "    if comp[\"distr name\"] == \"Poisson\":\n",
        "      data += list(np.random.poisson(comp[\"params\"][0], size=int(comp[\"pi\"] * n)))\n",
        "    if comp[\"distr name\"] == \"Bernoulli\":\n",
        "      data += list(np.random.binomial(1, comp[\"params\"][0], size=int(comp[\"pi\"] * n)))\n",
        "    if comp[\"distr name\"] == \"Binomial\":\n",
        "      data += list(np.random.binomial(comp[\"params\"][0], comp[\"params\"][1], size=int(comp[\"pi\"] * n)))\n",
        "  return data, true_components\n",
        "  ############################################\n",
        "def best_pi_match_distance(pi_a, pi_b):\n",
        "    \"\"\"\n",
        "    Returns (min_L1, best_perm_pi_b).\n",
        "    Tries all permutations of pi_b (OK up to K=8).\n",
        "    \"\"\"\n",
        "    k = len(pi_a)\n",
        "    best = None\n",
        "    best_perm = None\n",
        "    for perm in permutations(range(k)):\n",
        "        perm_b = [pi_b[j] for j in perm]\n",
        "        dist = sum(abs(a - b) for a, b in zip(pi_a, perm_b))\n",
        "        if best is None or dist < best:\n",
        "            best = dist\n",
        "            best_perm = perm_b\n",
        "    return best, best_perm\n",
        "\n",
        "def do_test(iter = 10):\n",
        "\n",
        "  num_test = 20\n",
        "\n",
        "  difflistpi = []\n",
        "  dis_notlist= []\n",
        "  for i in range(num_test):\n",
        "    decide = rd.randint(0, 1)\n",
        "    dis_or_not = decide\n",
        "    if decide == 0:\n",
        "      data, true_components = give_data_with_mixes_distribs_continuous()\n",
        "\n",
        "    if decide == 1:\n",
        "      data, true_components = give_data_with_mixes_distribs_discrete()\n",
        "\n",
        "    MCMC_pi = EM_MCMC(data, true_components, iter)\n",
        "    EM_pi = EM(data, true_components, iter)\n",
        "\n",
        "    L1, _ = best_pi_match_distance(EM_pi, MCMC_pi)\n",
        "    difflistpi.append(L1)\n",
        "    dis_notlist.append(dis_or_not)\n",
        "\n",
        "  colors = ['blue' if dis_notlist[i] == 0 else 'red' for i in range(len(dis_notlist))]\n",
        "  import matplotlib.patches as mpatches\n",
        "  leg = [\n",
        "      mpatches.Patch(color='blue', label='continuous'),\n",
        "      mpatches.Patch(color='red', label='discrete')\n",
        "  ]\n",
        "\n",
        "  plt.scatter(range(len(difflistpi)), difflistpi, c=colors)\n",
        "  plt.xlabel(\"Iteration\")\n",
        "  plt.ylabel(\"Difference in pi values\")\n",
        "  plt.legend(handles=leg)\n",
        "  plt.show()\n",
        "\n",
        "do_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "RqaILNfEEUA4",
        "outputId": "7f545e41-2d09-4b0d-b4f3-8f789adb792f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This uses the fact that we know what distributions are being generated to our advantage. It also utilizes the random function for multiple decisions - if we are going discrete or if not (decided to seperate because of the experiment that happened earlier when combining the 2 together).\n",
        "\n",
        "Chatgpt was used here for cleanup of the code in the previous segments, in which I had to argue for it to not do too much to the code.\n",
        "\n",
        "The graph shows the absolute differences in our finished mixing weights for each mixing we randomly selected. We see that the differences are quite random, which is what we should expect - the graph doesn't serve much meaning, only for a look into seeing what is happening under the hood more.\n",
        "\n"
      ],
      "metadata": {
        "id": "jAYXd0qgE3ly"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our brief analysid of these 2 method for Expectation Maximizimation, I've found that:\n",
        "\n",
        "- The Monte Carlo method requires more computation and has higher complexity than that of the Normal EM.\n",
        "\n",
        "- That being said, Monte Carlo gave surprisingly similar results, making it a viable alternative for EM."
      ],
      "metadata": {
        "id": "scAKFwIcJGUG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI USE:\n",
        "\n",
        "MODEL(S): CHATGPT 4o\n",
        "DATE: JULY 18TH-22ND\n",
        "PROMPTS ENTERED:\n",
        "\n",
        "- \"computing MLE for a mixture of distributions from dat\n",
        "\n",
        "\n",
        "- \"what is this log likelihood telling us for this iteration\"\n",
        "\n",
        "- \"why would the sum be 0 if the data fit perfected\"\n",
        "\n",
        "\n",
        "- \"give me a good dataset to use this on\"\n",
        "\n",
        "- \"this doesnt seem to give me accurate results\"\n",
        "\n",
        "- \"lambda x, mu=mu, sigma=sigma:\n",
        "what does this line mean\"\n",
        "\n",
        "- \"are u talking about it being (count_i + 1e-6) / total? for 4.\"\n",
        "\n",
        "- \"is there possibly other problems in my code\"\n",
        "\n",
        "- \"is there a trendline function for plt\"\n",
        "\n",
        "- \"coeffs = np.polyfit(range(len(ll_list)), ll_list, deg=3)\n",
        "  trendline = np.poly(coeffs)\n",
        "does this work\"\n",
        "\n",
        "- \"Component 1: Poisson, count = 236\n",
        "\n",
        "  Component 2: Exponential, count = 17088\n",
        "\n",
        "  ...\n",
        "\n",
        "  Final parameters:\n",
        "  Component 1: Normal\n",
        "  Parameters: 2.0323434577749007 0.5859832865135821\n",
        "  Weight: 0.42520000003333336\n",
        "\n",
        "  Component 2: Poisson\n",
        "  Parameters: 5.834782608695652\n",
        "  Weight: 0.0076666667\n",
        "\n",
        "  Component 3: Exponential\n",
        "  Parameters: 2.442350628306393\n",
        "  Weight: 0.5671333333666667\n",
        "\n",
        "  what can u say about this information and the problems with the mixtures\"\n",
        "\n",
        "- \"how would I change my poission initialization\"\n",
        "\n",
        "- \"Its better, but still seeing problems with poisson\"\n",
        "\n",
        "- \"what is the formula for responsibilities\"\n",
        "\n",
        "- \"If we have data that is from a binomial distribution that we don't know what p is, how can we estimate p\"\n",
        "\n",
        "- \"how would we do update of params in binomial\"\n",
        "\n",
        "- \"... Iteration 26: Log-likelihood = -1088.0312403030805\n",
        "  Component 0: Poisson, count = 18000\n",
        "  Component 1: Binomial, count = 12000\n",
        "\n",
        "  Iteration 27: Log-likelihood = -1088.0312403030805\n",
        "  Component 0: Poisson, count = 18000\n",
        "  Component 1: Binomial, count = 12000\n",
        "\n",
        "  Iteration 28: Log-likelihood = -1088.0312403030805\n",
        "  Component 0: Poisson, count = 18000\n",
        "  Component 1: Binomial, count = 12000\n",
        "\n",
        "  Iteration 29: Log-likelihood = -1088.0312403030805\n",
        "  Component 0: Poisson, count = 18000\n",
        "  Component 1: Binomial, count = 12000\n",
        "\n",
        "  Iteration 30: Log-likelihood = -1088.0312403030805\n",
        "\n",
        "  why output do this\"\n",
        "\n",
        "\n",
        "- \"clean up this code and make it look nice, and provide comments and help to all the functions\"\n",
        "\n",
        "- \"u removed the try and except things in here, doesn't that cause issues if I pick something bad\"\n",
        "\n",
        "- \"clean up this code and make it look nice, and provide comments and help to all the functions\n",
        "I TOLD YOU NOT TO REMOVE ANYTHING AND YOU REMOVED THE TRY AND EXCEPT, KEEP IT IN AND STILL MAKE EVERYTHING LOOK PRETTY AND HAVE AA HELP FOR FUNCTIONS\"\n",
        "\n",
        "- \"now comment on this code and clean it up\"\n",
        "\n",
        "- \"convert this such that all the user inputs are done by the computer for a given answer\"\n",
        "\n",
        "- \"how do classes work\"\n",
        "\n",
        "- \"can you change the name of the functions such that none of them have the same name, u will also have to look through the code for old function name and change that \"\n",
        "\n",
        "- \"am I missing anything, I want to make random samples of random mixes of either discrete or continuous mixes and then test the differences in pi with EM and EM MCMC ways\"\n",
        "\n",
        "- \"What are all the steps associated in expectation maximization\"\n",
        "\n",
        "- \"The M-step: We update the mixing weights by the average of the probability of data point $x$ coming from distribution $j$ for all $x$ in the data set.\n",
        "\n",
        "  is this worded right?\"\n",
        "\n",
        "- \"can u put this in Latex\""
      ],
      "metadata": {
        "id": "TfZ3JAWdJ1vP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Catalog/Backup"
      ],
      "metadata": {
        "id": "f-fp4zMyEpnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making Random Mixes and testing both EM and EMMC and comparing"
      ],
      "metadata": {
        "id": "yo4EseTYHbA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "#---------------- Distribution Picker ----------------#\n",
        "def pick_distribution(answer):\n",
        "    \"\"\"\n",
        "    Automatically assigns parameters and returns (pdf, param_tuple)\n",
        "    based on the chosen distribution name.\n",
        "    \"\"\"\n",
        "\n",
        "    if answer == \"Uniform\":\n",
        "        a0 = random.randint(0, 5)\n",
        "        b0 = random.randint(a0 + 1, a0 + 8)  # ensure b > a\n",
        "        def pdf(x): return 1 / (b0 - a0) if a0 <= x <= b0 else 0\n",
        "        return pdf, (a0, b0)\n",
        "\n",
        "    if answer == \"Exponential\":\n",
        "        theta0 = random.uniform(0.5, 5.0)\n",
        "        def pdf(x): return (1 / theta0) * math.exp(-x / theta0) if x >= 0 else 0\n",
        "        return pdf, (theta0,)\n",
        "\n",
        "    if answer == \"Normal\":\n",
        "        mu0 = random.uniform(-5, 5)\n",
        "        sigma0 = random.uniform(0.5, 3.0)\n",
        "        def pdf(x): return (1 / (sigma0 * math.sqrt(2 * math.pi))) * math.exp(-(x - mu0)**2 / (2 * sigma0**2))\n",
        "        return pdf, (mu0, sigma0)\n",
        "\n",
        "    if answer == \"Poisson\":\n",
        "        lambda_val = random.uniform(1, 8)\n",
        "        def pdf(x):\n",
        "            if x >= 0 and float(x).is_integer():\n",
        "                x_int = int(x)\n",
        "                log_pdf = -lambda_val + x_int * math.log(lambda_val) - math.lgamma(x_int + 1)\n",
        "                return math.exp(log_pdf)\n",
        "            return 0\n",
        "        return pdf, (lambda_val,)\n",
        "\n",
        "    if answer == \"Bernoulli\":\n",
        "        p = random.uniform(0.1, 0.9)\n",
        "        def pdf(x): return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "        return pdf, (p,)\n",
        "\n",
        "    raise ValueError(f\"Unsupported distribution name: {answer}\")\n",
        "\n",
        "#########################################EM Normal###############################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "\n",
        "#---------------- PDF Updater ----------------#\n",
        "def update_pdfs(components):\n",
        "    \"\"\"\n",
        "    After parameter updates, refresh each component's PDF.\n",
        "    \"\"\"\n",
        "    for comp in components:\n",
        "        name = comp[\"distr name\"]\n",
        "        params = comp[\"params\"]\n",
        "\n",
        "        if name == \"Normal\":\n",
        "            mu, sigma = params\n",
        "            comp[\"pdf\"] = lambda x, mu=mu, sigma=sigma: (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(-(x - mu)**2 / (2 * sigma**2))\n",
        "\n",
        "        elif name == \"Poisson\":\n",
        "            lamb = params[0]\n",
        "            comp[\"pdf\"] = lambda x, lamb=lamb: math.exp(-lamb + x * math.log(lamb) - math.lgamma(x + 1)) if x >= 0 and float(x).is_integer() else 0\n",
        "\n",
        "        elif name == \"Exponential\":\n",
        "            theta = params[0]\n",
        "            comp[\"pdf\"] = lambda x, theta=theta: (1 / theta) * math.exp(-x / theta) if x >= 0 else 0\n",
        "\n",
        "        elif name == \"Uniform\":\n",
        "            a, b = params\n",
        "            comp[\"pdf\"] = lambda x, a=a, b=b: 1 / (b - a) if a <= x <= b else 0\n",
        "\n",
        "        elif name == \"Bernoulli\":\n",
        "            p = params[0]\n",
        "            comp[\"pdf\"] = lambda x, p=p: p if x == 1 else (1 - p) if x == 0 else 0\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown distribution name: {name}\")\n",
        "\n",
        "#---------------- E-step ----------------#\n",
        "def e_step(data, components):\n",
        "    \"\"\"\n",
        "    Estimate responsibilities: P(z_i = j | x_i, θ)\n",
        "    \"\"\"\n",
        "    responsibilities = []\n",
        "    for x in data:\n",
        "        weighted_probs = [comp[\"pi\"] * comp[\"pdf\"](x) for comp in components]\n",
        "        total = sum(weighted_probs)\n",
        "        probs = [wp / total for wp in weighted_probs] if total > 0 else [1 / len(components)] * len(components)\n",
        "        responsibilities.append(probs)\n",
        "    return responsibilities\n",
        "\n",
        "#---------------- M-step ----------------#\n",
        "def m_step(data, responsibilities, components):\n",
        "    \"\"\"\n",
        "    Update weights and distribution parameters based on responsibilities.\n",
        "    \"\"\"\n",
        "    n = len(data)\n",
        "    k = len(components)\n",
        "\n",
        "    for i in range(k):\n",
        "        r_i = [resp[i] for resp in responsibilities]\n",
        "        total_r = sum(r_i)\n",
        "        components[i][\"pi\"] = total_r / n if total_r > 0 else 1e-6\n",
        "\n",
        "        weighted_data = [x * r for x, r in zip(data, r_i)]\n",
        "\n",
        "        name = components[i][\"distr name\"]\n",
        "\n",
        "        if name == \"Uniform\":\n",
        "            if np.sum(r_i) > 0:\n",
        "                x_array = np.array(data)\n",
        "                components[i][\"params\"] = (np.min(x_array), np.max(x_array))\n",
        "\n",
        "        elif name == \"Exponential\" and total_r > 0:\n",
        "            theta = sum(weighted_data) / total_r\n",
        "            components[i][\"params\"] = (theta,)\n",
        "\n",
        "        elif name == \"Normal\" and total_r > 0:\n",
        "            mu = sum(weighted_data) / total_r\n",
        "            var = sum(r * ((x - mu)**2) for x, r in zip(data, r_i)) / total_r\n",
        "            sigma = math.sqrt(var)\n",
        "            components[i][\"params\"] = (mu, sigma)\n",
        "\n",
        "        elif name == \"Bernoulli\" and total_r > 0:\n",
        "            p = sum(weighted_data) / total_r\n",
        "            components[i][\"params\"] = (p,)\n",
        "\n",
        "        elif name == \"Poisson\" and total_r > 0:\n",
        "            lambda_ = sum(weighted_data) / total_r\n",
        "            components[i][\"params\"] = (lambda_,)\n",
        "    update_pdfs(components)\n",
        "    return components\n",
        "#########################################EM MC###############################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "\n",
        "#---------------- E-Step (MCMC) ----------------#\n",
        "def e_step_MCMC(data, components, steps=100):\n",
        "    z_samples = []\n",
        "    k = len(components)\n",
        "    for x in data:\n",
        "        weights = [comp[\"pi\"] * comp[\"pdf\"](x) for comp in components]\n",
        "        total = sum(weights)\n",
        "        weights = [w / total for w in weights] if total > 0 else [1 / k] * k\n",
        "        z = np.random.choice(range(k), p=weights)\n",
        "        chain = []\n",
        "        for _ in range(steps):\n",
        "            if k > 1:\n",
        "                z_new = np.random.choice([j for j in range(k) if j != z])\n",
        "                if components[z_new][\"distr name\"] in {\"Poisson\", \"Bernoulli\"} and not float(x).is_integer():\n",
        "                    chain.append(z)\n",
        "                    continue\n",
        "                num = components[z_new][\"pi\"] * components[z_new][\"pdf\"](x)\n",
        "                den = components[z][\"pi\"] * components[z][\"pdf\"](x)\n",
        "                alpha = min(1, num / den if den > 0 else 1)\n",
        "                if np.random.rand() < alpha:\n",
        "                    z = z_new\n",
        "            chain.append(z)\n",
        "        z_samples.append(chain)\n",
        "    return z_samples\n",
        "\n",
        "\n",
        "#---------------- M-Step ----------------#\n",
        "def m_step_MCMC(z_samples, components):\n",
        "    flatz = [z for chain in z_samples for z in chain]\n",
        "    total = len(flatz)\n",
        "    eps = 1e-6\n",
        "    min_weight = 0.05\n",
        "    for i in range(len(components)):\n",
        "        count_i = flatz.count(i)\n",
        "        pi_i = (count_i + eps) / total\n",
        "        components[i][\"pi\"] = max(min_weight, pi_i)\n",
        "    total_pi = sum(comp[\"pi\"] for comp in components)\n",
        "    for comp in components:\n",
        "        comp[\"pi\"] /= total_pi\n",
        "    return components\n",
        "\n",
        "\n",
        "#---------------- Update Parameters ----------------#\n",
        "def update_params_pdfs(data, components, z_samples):\n",
        "    flat_x = [x for i, x in enumerate(data) for _ in z_samples[i]]\n",
        "    flat_z = [z for chain in z_samples for z in chain]\n",
        "    for i, comp in enumerate(components):\n",
        "        spec_data = [x for x, z in zip(flat_x, flat_z) if z == i]\n",
        "        if not spec_data:\n",
        "            continue\n",
        "        name = comp[\"distr name\"]\n",
        "        if name == \"Uniform\":\n",
        "            comp[\"params\"] = (min(spec_data), max(spec_data))\n",
        "        elif name == \"Exponential\":\n",
        "            comp[\"params\"] = (np.mean(spec_data),)\n",
        "        elif name == \"Normal\":\n",
        "            comp[\"params\"] = (np.mean(spec_data), np.std(spec_data))\n",
        "        elif name == \"Bernoulli\":\n",
        "            comp[\"params\"] = (np.mean(spec_data),)\n",
        "        elif name == \"Poisson\":\n",
        "            comp[\"params\"] = (np.mean(spec_data),)\n",
        "\n",
        "        # Update pdfs\n",
        "        params = comp[\"params\"]\n",
        "        if name == \"Normal\":\n",
        "            mu, sigma = params\n",
        "            comp[\"pdf\"] = lambda x, mu=mu, sigma=sigma: (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(-(x - mu)**2 / (2 * sigma**2))\n",
        "        elif name == \"Poisson\":\n",
        "            lamb = params[0]\n",
        "            comp[\"pdf\"] = lambda x, lamb=lamb: math.exp(-lamb + x * math.log(lamb) - math.lgamma(x + 1)) if x >= 0 and float(x).is_integer() else 0\n",
        "        elif name == \"Exponential\":\n",
        "            theta = params[0]\n",
        "            comp[\"pdf\"] = lambda x, theta=theta: (1 / theta) * math.exp(-x / theta) if x >= 0 else 0\n",
        "        elif name == \"Uniform\":\n",
        "            a, b = params\n",
        "            comp[\"pdf\"] = lambda x, a=a, b=b: 1 / (b - a) if a <= x <= b else 0\n",
        "        elif name == \"Bernoulli\":\n",
        "            p = params[0]\n",
        "            comp[\"pdf\"] = lambda x, p=p: p if x == 1 else (1 - p) if x == 0 else 0\n",
        "    return components\n",
        "\n",
        "#---------------- EM-MCMC Main ----------------#\n",
        "def EM_MCMC(data, true_comps, iter = 25):\n",
        "\n",
        "    complen = len(true_comps)\n",
        "    components = []\n",
        "    for i in range(complen):\n",
        "      distr = true_comps[i][\"distr name\"]\n",
        "      pdf_f, param = pick_distribution(distr)\n",
        "      components.append({\n",
        "          \"distr name\": distr,\n",
        "          \"pdf\": pdf_f,\n",
        "          \"params\": param,\n",
        "          \"pi\": 1/complen # we assume dont know the exact mix of the data\n",
        "      })\n",
        "\n",
        "    for i in range(iter):\n",
        "        z_samples = e_step_MCMC(data, components)\n",
        "        components = m_step_MCMC(z_samples, components)\n",
        "        components = update_params_pdfs(data, components, z_samples)\n",
        "\n",
        "    return [components[i]['pi'] for i in range(complen)]\n",
        "\n",
        "#---------------- EM Main ----------------#\n",
        "def EM(data, true_comps, iter = 25):\n",
        "\n",
        "    num_components = len(true_comps)\n",
        "    components = []\n",
        "    for i in range(num_components):\n",
        "        distr = true_comps[i][\"distr name\"]\n",
        "        pdf_f, param = pick_distribution(distr)\n",
        "        components.append({\n",
        "            \"distr name\": distr,\n",
        "            \"pdf\": pdf_f,\n",
        "            \"params\": param,\n",
        "            \"pi\": 1 / num_components\n",
        "        })\n",
        "\n",
        "    for i in range(iter):\n",
        "        responsibilities = e_step(data, components)\n",
        "        components = m_step(data, responsibilities, components)\n",
        "\n",
        "    return [components[i]['pi'] for i in range(num_components)]\n",
        "\n",
        "\n",
        "\n",
        "import random as rd\n",
        "\n",
        "\n",
        "def give_data_with_mixes_distribs_continuous():\n",
        "\n",
        "  num_mixes = rd.randint(2, 8)\n",
        "\n",
        "  distributions = [\"Uniform\", \"Exponential\", \"Normal\"]\n",
        "  components = []\n",
        "\n",
        "  true_components = []\n",
        "  sum = 0\n",
        "  for i in range(num_mixes):\n",
        "        distr = rd.choice(distributions)\n",
        "        pdf_f, param = pick_distribution(distr)\n",
        "        pi_i = rd.uniform(0, 1 - sum)\n",
        "        sum += pi_i\n",
        "        true_components.append({\n",
        "            \"distr name\": distr,\n",
        "            \"pdf\": pdf_f,\n",
        "            \"params\": param,\n",
        "            \"pi\": pi_i\n",
        "        })\n",
        "  # create data\n",
        "  data = []\n",
        "  n = rd.randint(5, 1000)\n",
        "  for comp in true_components:\n",
        "    if comp[\"distr name\"] == \"Uniform\":\n",
        "      data += list(np.random.uniform(comp[\"params\"][0], comp[\"params\"][1], size=int(comp[\"pi\"] * n)))\n",
        "    if comp[\"distr name\"] == \"Exponential\":\n",
        "      data += list(np.random.exponential(comp[\"params\"][0], size=int(comp[\"pi\"] * n)))\n",
        "    if comp[\"distr name\"] == \"Normal\":\n",
        "      data += list(np.random.normal(comp[\"params\"][0], comp[\"params\"][1], size=int(comp[\"pi\"] * n)))\n",
        "  return data, true_components\n",
        "  ############################################\n",
        "\n",
        "def give_data_with_mixes_distribs_discrete():\n",
        "\n",
        "  num_mixes = rd.randint(2, 8)\n",
        "\n",
        "  distributions = [\"Poisson\", \"Bernoulli\"]\n",
        "  components = []\n",
        "\n",
        "  true_components = []\n",
        "  sum = 0\n",
        "  for i in range(num_mixes):\n",
        "        distr = rd.choice(distributions)\n",
        "        pdf_f, param = pick_distribution(distr)\n",
        "        pi_i = rd.uniform(0, 1 - sum)\n",
        "        sum += pi_i\n",
        "        true_components.append({\n",
        "            \"distr name\": distr,\n",
        "            \"pdf\": pdf_f,\n",
        "            \"params\": param,\n",
        "            \"pi\": pi_i\n",
        "        })\n",
        "  # create data\n",
        "  data = []\n",
        "  n = rd.randint(5, 1000)\n",
        "  for comp in true_components:\n",
        "    if comp[\"distr name\"] == \"Poisson\":\n",
        "      data += list(np.random.poisson(comp[\"params\"][0], size=int(comp[\"pi\"] * n)))\n",
        "    if comp[\"distr name\"] == \"Bernoulli\":\n",
        "      data += list(np.random.binomial(1, comp[\"params\"][0], size=int(comp[\"pi\"] * n)))\n",
        "    if comp[\"distr name\"] == \"Binomial\":\n",
        "      data += list(np.random.binomial(comp[\"params\"][0], comp[\"params\"][1], size=int(comp[\"pi\"] * n)))\n",
        "  return data, true_components\n",
        "  ############################################\n",
        "\n",
        "def do_test(iter = 25):\n",
        "\n",
        "  num_test = 20\n",
        "\n",
        "  difflistpi = []\n",
        "  for i in range(num_test):\n",
        "    decide = rd.randint(0, 1)\n",
        "    if decide == 0:\n",
        "      data, true_components = give_data_with_mixes_distribs_continuous()\n",
        "      MCMC_pi = EM_MCMC(data, true_components, iter)\n",
        "      EM_pi = EM(data, true_components, iter)\n",
        "    if decide == 1:\n",
        "      data, true_components = give_data_with_mixes_distribs_discrete()\n",
        "      MCMC_pi = EM_MCMC(data, true_components, iter)\n",
        "      EM_pi = EM(data, true_components, iter)\n",
        "    #differences in pi\n",
        "    diff_pi = [abs(MCMC_pi[i] - EM_pi[i]) for i in range(len(MCMC_pi))]\n",
        "    #list of differences\n",
        "    difflistpi.append(sum(diff_pi))\n",
        "    print([round(diff, 6) for diff in diff_pi])\n",
        "\n",
        "  plt.scatter(range(len(difflistpi)), difflistpi, label='')\n",
        "  plt.xlabel(\"Iteration\")\n",
        "  plt.ylabel(\"Difference in pi values\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "do_test()\n",
        "\n"
      ],
      "metadata": {
        "id": "YxxDV--qHahX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using MCMC instead of Normal EM"
      ],
      "metadata": {
        "id": "3A3pf_UrPcX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "\n",
        "#########################################EM MC###############################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#---------------- Safe Binomial PDF ----------------#\n",
        "def binomial_pdf_safe(x, n, p):\n",
        "    \"\"\"Computes binomial PMF using log-form to avoid overflow.\"\"\"\n",
        "    if 0 <= x <= n:\n",
        "        try:\n",
        "            log_pdf = (math.lgamma(n + 1)\n",
        "                       - math.lgamma(x + 1)\n",
        "                       - math.lgamma(n - x + 1)\n",
        "                       + x * math.log(p)\n",
        "                       + (n - x) * math.log(1 - p))\n",
        "            return math.exp(log_pdf)\n",
        "        except (ValueError, OverflowError):\n",
        "            return 0\n",
        "    return 0\n",
        "\n",
        "\n",
        "#---------------- Distribution Picker ----------------#\n",
        "def pick_distribution(answer):\n",
        "    \"\"\"\n",
        "    Prompts user for parameters of the chosen distribution.\n",
        "    Returns a tuple: (pdf function, parameter tuple)\n",
        "    \"\"\"\n",
        "\n",
        "    if answer == \"Uniform\":\n",
        "        while True:\n",
        "            try:\n",
        "                a0 = float(input(\"Initial lower bound guess: \"))\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        while True:\n",
        "            try:\n",
        "                b0 = float(input(\"Initial upper bound guess: \"))\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        def pdf(x): return 1 / (b0 - a0) if a0 <= x <= b0 else 0\n",
        "        return pdf, (a0, b0)\n",
        "\n",
        "    if answer == \"Exponential\":\n",
        "        while True:\n",
        "            try:\n",
        "                theta0 = float(input(\"Enter the mean guess: \"))\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        def pdf(x): return (1 / theta0) * math.exp(-x / theta0) if x >= 0 else 0\n",
        "        return pdf, (theta0,)\n",
        "\n",
        "    if answer == \"Normal\":\n",
        "        while True:\n",
        "            try:\n",
        "                mu0 = float(input(\"Enter the mean guess: \"))\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        while True:\n",
        "            try:\n",
        "                sigma0 = float(input(\"Enter the standard deviation guess: \"))\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        def pdf(x): return (1 / (sigma0 * math.sqrt(2 * math.pi))) * math.exp(-(x - mu0)**2 / (2 * sigma0**2))\n",
        "        return pdf, (mu0, sigma0)\n",
        "\n",
        "    if answer == \"Poisson\":\n",
        "        integer_data = [x for x in data if float(x).is_integer()]\n",
        "        estimated_lambda = np.mean(integer_data) if integer_data else 3.0\n",
        "        print(f\"Suggested lambda (from integer data): {estimated_lambda:.2f}\")\n",
        "        while True:\n",
        "            try:\n",
        "                lambda_val = float(input(\"Enter the Poisson mean (lambda): \"))\n",
        "                if lambda_val > 0:\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"Lambda must be greater than 0.\")\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        def pdf(x):\n",
        "            if x >= 0 and float(x).is_integer():\n",
        "                x_int = int(x)\n",
        "                log_pdf = -lambda_val + x_int * math.log(lambda_val) - math.lgamma(x_int + 1)\n",
        "                return math.exp(log_pdf)\n",
        "            return 0\n",
        "        return pdf, (lambda_val,)\n",
        "\n",
        "    if answer == \"Bernoulli\":\n",
        "        while True:\n",
        "            try:\n",
        "                p = float(input(\"Enter probability of success (0 < p < 1): \"))\n",
        "                if 0 < p < 1:\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"p must be between 0 and 1.\")\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        def pdf(x): return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "        return pdf, (p,)\n",
        "\n",
        "    if answer == \"Binomial\":\n",
        "        n = 300  # Reasonable default\n",
        "        while True:\n",
        "            try:\n",
        "                p = float(input(\"Enter probability of success (0 < p < 1): \"))\n",
        "                if 0 < p < 1:\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"p must be between 0 and 1.\")\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        def pdf(x): return binomial_pdf_safe(x, n, p)\n",
        "        return pdf, (n, p)\n",
        "\n",
        "\n",
        "#---------------- E-Step (MCMC) ----------------#\n",
        "def e_step_MCMC(data, components, steps=100):\n",
        "    z_samples = []\n",
        "    k = len(components)\n",
        "    for x in data:\n",
        "        weights = [comp[\"pi\"] * comp[\"pdf\"](x) for comp in components]\n",
        "        total = sum(weights)\n",
        "        weights = [w / total for w in weights] if total > 0 else [1 / k] * k\n",
        "        z = np.random.choice(range(k), p=weights)\n",
        "        chain = []\n",
        "        for _ in range(steps):\n",
        "            if k > 1:\n",
        "                z_new = np.random.choice([j for j in range(k) if j != z])\n",
        "                if components[z_new][\"distr name\"] in {\"Poisson\", \"Bernoulli\", \"Binomial\"} and not float(x).is_integer():\n",
        "                    chain.append(z)\n",
        "                    continue\n",
        "                num = components[z_new][\"pi\"] * components[z_new][\"pdf\"](x)\n",
        "                den = components[z][\"pi\"] * components[z][\"pdf\"](x)\n",
        "                alpha = min(1, num / den if den > 0 else 1)\n",
        "                if np.random.rand() < alpha:\n",
        "                    z = z_new\n",
        "            chain.append(z)\n",
        "        z_samples.append(chain)\n",
        "    return z_samples\n",
        "\n",
        "\n",
        "#---------------- M-Step ----------------#\n",
        "def m_step_MCMC(z_samples, components):\n",
        "    flatz = [z for chain in z_samples for z in chain]\n",
        "    total = len(flatz)\n",
        "    eps = 1e-6\n",
        "    min_weight = 0.05\n",
        "    for i in range(len(components)):\n",
        "        count_i = flatz.count(i)\n",
        "        pi_i = (count_i + eps) / total\n",
        "        components[i][\"pi\"] = max(min_weight, pi_i)\n",
        "    total_pi = sum(comp[\"pi\"] for comp in components)\n",
        "    for comp in components:\n",
        "        comp[\"pi\"] /= total_pi\n",
        "    return components\n",
        "\n",
        "\n",
        "#---------------- Update Parameters ----------------#\n",
        "def update_params_pdfs(data, components, z_samples):\n",
        "    flat_x = [x for i, x in enumerate(data) for _ in z_samples[i]]\n",
        "    flat_z = [z for chain in z_samples for z in chain]\n",
        "    for i, comp in enumerate(components):\n",
        "        spec_data = [x for x, z in zip(flat_x, flat_z) if z == i]\n",
        "        if not spec_data:\n",
        "            continue\n",
        "        name = comp[\"distr name\"]\n",
        "        if name == \"Uniform\":\n",
        "            comp[\"params\"] = (min(spec_data), max(spec_data))\n",
        "        elif name == \"Exponential\":\n",
        "            comp[\"params\"] = (np.mean(spec_data),)\n",
        "        elif name == \"Normal\":\n",
        "            comp[\"params\"] = (np.mean(spec_data), np.std(spec_data))\n",
        "        elif name == \"Bernoulli\":\n",
        "            comp[\"params\"] = (np.mean(spec_data),)\n",
        "        elif name == \"Poisson\":\n",
        "            comp[\"params\"] = (np.mean(spec_data),)\n",
        "        elif name == \"Binomial\":\n",
        "            n_old, _ = comp[\"params\"]\n",
        "            n = max(int(n_old), int(np.percentile(spec_data, 95)))\n",
        "            p_est = np.mean(spec_data) / n if n > 0 else 1e-6\n",
        "            p_est = max(1e-6, min(1 - 1e-6, p_est))\n",
        "            comp[\"params\"] = (n, p_est)\n",
        "\n",
        "        # Update pdfs\n",
        "        params = comp[\"params\"]\n",
        "        if name == \"Normal\":\n",
        "            mu, sigma = params\n",
        "            comp[\"pdf\"] = lambda x, mu=mu, sigma=sigma: (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(-(x - mu)**2 / (2 * sigma**2))\n",
        "        elif name == \"Poisson\":\n",
        "            lamb = params[0]\n",
        "            comp[\"pdf\"] = lambda x, lamb=lamb: math.exp(-lamb + x * math.log(lamb) - math.lgamma(x + 1)) if x >= 0 and float(x).is_integer() else 0\n",
        "        elif name == \"Exponential\":\n",
        "            theta = params[0]\n",
        "            comp[\"pdf\"] = lambda x, theta=theta: (1 / theta) * math.exp(-x / theta) if x >= 0 else 0\n",
        "        elif name == \"Uniform\":\n",
        "            a, b = params\n",
        "            comp[\"pdf\"] = lambda x, a=a, b=b: 1 / (b - a) if a <= x <= b else 0\n",
        "        elif name == \"Bernoulli\":\n",
        "            p = params[0]\n",
        "            comp[\"pdf\"] = lambda x, p=p: p if x == 1 else (1 - p) if x == 0 else 0\n",
        "        elif name == \"Binomial\":\n",
        "            n, p = params\n",
        "            comp[\"pdf\"] = lambda x, n=n, p=p: binomial_pdf_safe(x, n, p)\n",
        "    return components\n",
        "\n",
        "\n",
        "#---------------- Log-Likelihood ----------------#\n",
        "def compute_log_likelihood(data, components):\n",
        "    log_likelihood = 0\n",
        "    for x in data:\n",
        "        mix_prob = sum(comp[\"pi\"] * comp[\"pdf\"](x) for comp in components)\n",
        "        if mix_prob > 0:\n",
        "            log_likelihood += math.log(mix_prob)\n",
        "    return log_likelihood\n",
        "\n",
        "\n",
        "#---------------- EM-MCMC Main ----------------#\n",
        "def EM_MCMC(data, num_iters):\n",
        "    num_components = int(input(\"How many distributions would you like to mix? \"))\n",
        "    components = []\n",
        "    for i in range(num_components):\n",
        "        distr = \"\"\n",
        "        while distr not in [\"Uniform\", \"Exponential\", \"Normal\", \"Poisson\", \"Bernoulli\", \"Binomial\"]:\n",
        "            distr = input(f\"Choose distribution {i+1}: \")\n",
        "        pdf_f, param = pick_distribution(distr)\n",
        "        components.append({\"distr name\": distr, \"pdf\": pdf_f, \"params\": param, \"pi\": 1 / num_components})\n",
        "\n",
        "    ll_list = []\n",
        "    for i in range(num_iters):\n",
        "        z_samples = e_step_MCMC(data, components)\n",
        "        components = m_step_MCMC(z_samples, components)\n",
        "        components = update_params_pdfs(data, components, z_samples)\n",
        "        ll = compute_log_likelihood(data, components)\n",
        "        ll_list.append(ll)\n",
        "        if i > 0:\n",
        "            print(f\"Iteration {i+1}: Log-likelihood = {ll:.4f}\")\n",
        "\n",
        "    # Plot log-likelihood\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(range(len(ll_list)), ll_list, label='Log-Likelihood')\n",
        "    trendline = np.poly1d(np.polyfit(range(len(ll_list)), ll_list, deg=3))\n",
        "    plt.plot(range(len(ll_list)), trendline(range(len(ll_list))), color='blue', label='Trendline')\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Log-Likelihood\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Final parameter output\n",
        "    print(\"\\nFinal Parameters:\")\n",
        "    for i, comp in enumerate(components):\n",
        "        print(f\"Component {i+1}: {comp['distr name']}\")\n",
        "        print(\"  Parameters:\", *(round(float(x), 4) for x in comp[\"params\"]))\n",
        "        print(\"  Weight:    \", round(float(comp[\"pi\"]), 4))\n",
        "        print()\n",
        "\n",
        "\n",
        "#---------------- Entry Point ----------------#\n",
        "np.random.seed(924)\n",
        "n = 300\n",
        "data = []\n",
        "data += list(np.random.poisson(3, size=int(0.4 * n)))\n",
        "data += list(np.random.binomial(300, 0.5, size=int(0.6 * n)))\n",
        "random.shuffle(data)\n",
        "\n",
        "# Run\n",
        "EM_MCMC(data, 20)\n"
      ],
      "metadata": {
        "id": "2iISehNbxwUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "\n",
        "#########################################EM Normal###############################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#################################################################################################\n",
        "#---------------- Distribution Picker ----------------#\n",
        "def pick_distribution(answer):\n",
        "    \"\"\"\n",
        "    Asks the user for parameters depending on the distribution type.\n",
        "    Returns a PDF function and its initial parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    # Continuous Distributions ----------------------------\n",
        "\n",
        "    if answer == \"Uniform\":\n",
        "        while True:\n",
        "            try:\n",
        "                a0 = float(input(\"Initial lower bound guess: \"))\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        while True:\n",
        "            try:\n",
        "                b0 = float(input(\"Initial upper bound guess: \"))\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        def pdf(x):\n",
        "            return 1 / (b0 - a0) if a0 <= x <= b0 else 0\n",
        "        return pdf, (a0, b0)\n",
        "\n",
        "    if answer == \"Exponential\":\n",
        "        while True:\n",
        "            try:\n",
        "                theta0 = float(input(\"Enter the mean guess: \"))\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        def pdf(x):\n",
        "            return (1 / theta0) * math.exp(-x / theta0) if x >= 0 else 0\n",
        "        return pdf, (theta0,)\n",
        "\n",
        "    if answer == \"Normal\":\n",
        "        while True:\n",
        "            try:\n",
        "                mu0 = float(input(\"Enter the mean guess: \"))\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        while True:\n",
        "            try:\n",
        "                sigma0 = float(input(\"Enter the standard deviation guess: \"))\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        def pdf(x_val):\n",
        "            return (1 / (sigma0 * math.sqrt(2 * math.pi))) * math.exp(-(x_val - mu0)**2 / (2 * sigma0**2))\n",
        "        return pdf, (mu0, sigma0)\n",
        "\n",
        "    # Discrete Distributions ----------------------------\n",
        "\n",
        "    if answer == \"Poisson\":\n",
        "        integer_data = [x for x in data if float(x).is_integer()]\n",
        "        estimated_lambda = np.mean(integer_data) if integer_data else 3.0\n",
        "        print(f\"Suggested lambda (from integer data): {estimated_lambda:.2f}\")\n",
        "        while True:\n",
        "            try:\n",
        "                lambda_val = float(input(\"Enter the Poisson mean (lambda): \"))\n",
        "                if lambda_val > 0:\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"lambda must be greater than 0.\")\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        def pdf(x):\n",
        "            if x >= 0 and float(x).is_integer():\n",
        "                x_int = int(x)\n",
        "                log_pdf = -lambda_val + x_int * math.log(lambda_val) - math.lgamma(x_int + 1)\n",
        "                return math.exp(log_pdf)\n",
        "            return 0\n",
        "        return pdf, (lambda_val,)\n",
        "\n",
        "    if answer == \"Bernoulli\":\n",
        "        while True:\n",
        "            try:\n",
        "                p = float(input(\"Enter probability of success (0 < p < 1): \"))\n",
        "                if 0 < p < 1:\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"p must be between 0 and 1.\")\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        def pdf(x):\n",
        "            return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "        return pdf, (p,)\n",
        "\n",
        "    if answer == \"Binomial\":\n",
        "        n = max(data)\n",
        "        while True:\n",
        "            try:\n",
        "                p = float(input(\"Enter probability of success (0 < p < 1): \"))\n",
        "                if 0 < p < 1:\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"p must be between 0 and 1.\")\n",
        "            except ValueError:\n",
        "                print(\"Invalid input. Please enter a number.\")\n",
        "        def pdf(x):\n",
        "            if 0 <= x <= n:\n",
        "                return math.comb(n, x) * (p ** x) * ((1 - p) ** (n - x))\n",
        "            return 0\n",
        "        return pdf, (n, p)\n",
        "\n",
        "#---------------- PDF Updater ----------------#\n",
        "def update_pdfs(components):\n",
        "    \"\"\"\n",
        "    After parameter updates, refresh each component's PDF.\n",
        "    \"\"\"\n",
        "    for comp in components:\n",
        "        name = comp[\"distr name\"]\n",
        "        params = comp[\"params\"]\n",
        "\n",
        "        if name == \"Normal\":\n",
        "            mu, sigma = params\n",
        "            comp[\"pdf\"] = lambda x, mu=mu, sigma=sigma: (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(-(x - mu)**2 / (2 * sigma**2))\n",
        "\n",
        "        elif name == \"Poisson\":\n",
        "            lamb = params[0]\n",
        "            comp[\"pdf\"] = lambda x, lamb=lamb: math.exp(-lamb + x * math.log(lamb) - math.lgamma(x + 1)) if x >= 0 and float(x).is_integer() else 0\n",
        "\n",
        "        elif name == \"Exponential\":\n",
        "            theta = params[0]\n",
        "            comp[\"pdf\"] = lambda x, theta=theta: (1 / theta) * math.exp(-x / theta) if x >= 0 else 0\n",
        "\n",
        "        elif name == \"Uniform\":\n",
        "            a, b = params\n",
        "            comp[\"pdf\"] = lambda x, a=a, b=b: 1 / (b - a) if a <= x <= b else 0\n",
        "\n",
        "        elif name == \"Bernoulli\":\n",
        "            p = params[0]\n",
        "            comp[\"pdf\"] = lambda x, p=p: p if x == 1 else (1 - p) if x == 0 else 0\n",
        "\n",
        "        elif name == \"Binomial\":\n",
        "            n, p = params\n",
        "            comp[\"pdf\"] = lambda x, n=n, p=p: math.comb(n, x) * (p ** x) * ((1 - p) ** (n - x)) if 0 <= x <= n else 0\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown distribution name: {name}\")\n",
        "\n",
        "#---------------- E-step ----------------#\n",
        "def e_step(data, components):\n",
        "    \"\"\"\n",
        "    Estimate responsibilities: P(z_i = j | x_i, θ)\n",
        "    \"\"\"\n",
        "    responsibilities = []\n",
        "    for x in data:\n",
        "        weighted_probs = [comp[\"pi\"] * comp[\"pdf\"](x) for comp in components]\n",
        "        total = sum(weighted_probs)\n",
        "        probs = [wp / total for wp in weighted_probs] if total > 0 else [1 / len(components)] * len(components)\n",
        "        responsibilities.append(probs)\n",
        "    return responsibilities\n",
        "\n",
        "#---------------- M-step ----------------#\n",
        "def m_step(data, responsibilities, components):\n",
        "    \"\"\"\n",
        "    Update weights and distribution parameters based on responsibilities.\n",
        "    \"\"\"\n",
        "    n = len(data)\n",
        "    k = len(components)\n",
        "\n",
        "    for i in range(k):\n",
        "        r_i = [resp[i] for resp in responsibilities]\n",
        "        total_r = sum(r_i)\n",
        "        components[i][\"pi\"] = total_r / n if total_r > 0 else 1e-6\n",
        "\n",
        "        weighted_data = [x * r for x, r in zip(data, r_i)]\n",
        "\n",
        "        name = components[i][\"distr name\"]\n",
        "\n",
        "        if name == \"Uniform\":\n",
        "            if np.sum(r_i) > 0:\n",
        "                x_array = np.array(data)\n",
        "                components[i][\"params\"] = (np.min(x_array), np.max(x_array))\n",
        "\n",
        "        elif name == \"Exponential\" and total_r > 0:\n",
        "            theta = sum(weighted_data) / total_r\n",
        "            components[i][\"params\"] = (theta,)\n",
        "\n",
        "        elif name == \"Normal\" and total_r > 0:\n",
        "            mu = sum(weighted_data) / total_r\n",
        "            var = sum(r * ((x - mu)**2) for x, r in zip(data, r_i)) / total_r\n",
        "            sigma = math.sqrt(var)\n",
        "            components[i][\"params\"] = (mu, sigma)\n",
        "\n",
        "        elif name == \"Bernoulli\" and total_r > 0:\n",
        "            p = sum(weighted_data) / total_r\n",
        "            components[i][\"params\"] = (p,)\n",
        "\n",
        "        elif name == \"Poisson\" and total_r > 0:\n",
        "            lambda_ = sum(weighted_data) / total_r\n",
        "            components[i][\"params\"] = (lambda_,)\n",
        "\n",
        "        elif name == \"Binomial\":\n",
        "            n_old, _ = components[i][\"params\"]\n",
        "            n_int = int(n_old)\n",
        "            if total_r > 0:\n",
        "                weighted_sum = sum(x * r for x, r in zip(data, r_i))\n",
        "                p_estimate = weighted_sum / (n_int * total_r)\n",
        "                p_estimate = max(1e-6, min(1 - 1e-6, p_estimate))\n",
        "                components[i][\"params\"] = (n_int, p_estimate)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown distribution name: {name}\")\n",
        "\n",
        "    update_pdfs(components)\n",
        "    return components\n",
        "\n",
        "#---------------- Log-Likelihood ----------------#\n",
        "def compute_log_likelihood(data, components):\n",
        "    \"\"\"\n",
        "    Computes the total log-likelihood of the current model.\n",
        "    \"\"\"\n",
        "    ll = 0\n",
        "    for x in data:\n",
        "        prob = sum(comp[\"pi\"] * comp[\"pdf\"](x) for comp in components)\n",
        "        if prob > 0:\n",
        "            ll += np.log(prob)\n",
        "    return ll\n",
        "\n",
        "#---------------- EM Main ----------------#\n",
        "def EM_MCMC(data, num_iters):\n",
        "    \"\"\"\n",
        "    Expectation-Maximization algorithm for mixture models (non-MCMC version).\n",
        "    \"\"\"\n",
        "    num_components = int(input(\"How many distributions would you like to mix? \"))\n",
        "    components = []\n",
        "    for i in range(num_components):\n",
        "        distr = ''\n",
        "        while distr not in [\"Uniform\", \"Exponential\", \"Normal\", \"Poisson\", \"Bernoulli\", \"Binomial\"]:\n",
        "            distr = input(f\"Choose distribution {i+1}: \")\n",
        "        pdf_f, param = pick_distribution(distr)\n",
        "        components.append({\n",
        "            \"distr name\": distr,\n",
        "            \"pdf\": pdf_f,\n",
        "            \"params\": param,\n",
        "            \"pi\": 1 / num_components\n",
        "        })\n",
        "\n",
        "    ll_list = []\n",
        "    for i in range(num_iters):\n",
        "        responsibilities = e_step(data, components)\n",
        "        components = m_step(data, responsibilities, components)\n",
        "        ll = compute_log_likelihood(data, components)\n",
        "        ll_list.append(ll)\n",
        "        if i > 0:\n",
        "            print(f\"Iteration {i+1}: Log-likelihood = {ll:.4f}\")\n",
        "\n",
        "    # Plotting log-likelihood over iterations\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(range(len(ll_list)), ll_list, label='Log-Likelihood')\n",
        "    trendline = np.poly1d(np.polyfit(range(len(ll_list)), ll_list, deg=3))\n",
        "    plt.plot(range(len(ll_list)), trendline(range(len(ll_list))), color='blue', label='Trendline')\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Log-Likelihood\")\n",
        "    plt.legend()\n",
        "    plt.title(\"EM Log-Likelihood Progress\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Final output\n",
        "    print(\"\\nFinal parameters:\")\n",
        "    for i, comp in enumerate(components):\n",
        "        print(f\"Component {i+1}: {comp['distr name']}\")\n",
        "        print(\"  Parameters:\", *(round(float(x), 4) for x in comp[\"params\"]))\n",
        "        print(\"  Weight:    \", round(float(comp[\"pi\"]), 4))\n",
        "        print()\n",
        "\n",
        "#---------------- Main Execution ----------------#\n",
        "np.random.seed(924)\n",
        "n = 300\n",
        "data = []\n",
        "\n",
        "# Data mixture: 40% Poisson(3), 60% Binomial(300, 0.5)\n",
        "data += list(np.random.poisson(3, size=int(0.4 * n)))\n",
        "data += list(np.random.binomial(300, 0.5, size=int(0.6 * n)))\n",
        "random.shuffle(data)\n",
        "\n",
        "# Run EM\n",
        "EM_MCMC(data, 200)\n"
      ],
      "metadata": {
        "id": "1H7gnzEdz7fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classical EM"
      ],
      "metadata": {
        "id": "0m2auEtECAsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import functools\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def pick_distribution(answer):\n",
        "\n",
        "  #Continuous Distributions-----------------------------------------------------\n",
        "\n",
        "  if answer == \"Uniform\":\n",
        "    while True:\n",
        "      try:\n",
        "        a0 = float(input(\"Initial lower bound guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    while True:\n",
        "      try:\n",
        "        b0 = float(input(\"Initial upper bound guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x):\n",
        "      return 1 / (b0 - a0) if a0 <= x <= b0 else 0\n",
        "\n",
        "    return pdf, (a0, b0)\n",
        "\n",
        "  if answer == \"Exponential\":\n",
        "    while True:\n",
        "      try:\n",
        "        theta0 = float(input(\"Enter the mean guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    def pdf(x):\n",
        "      return (1 / theta0) * math.exp(-x / theta0) if x >= 0 else 0\n",
        "\n",
        "    return pdf, (theta0,) # Corrected parameter return\n",
        "\n",
        "  if answer == \"Normal\":\n",
        "    while True:\n",
        "      try:\n",
        "        mu0 = float(input(\"Enter the mean guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    while True:\n",
        "      try:\n",
        "        sigma0 = float(input(\"Enter the standard deviation guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x_val):\n",
        "      return (1 / (sigma0 * math.sqrt(2 * math.pi))) * math.exp(-(x_val - mu0)**2 / (2 * sigma0**2))\n",
        "    return pdf, (mu0, sigma0)\n",
        "\n",
        "\n",
        "  #Discrete Distributions-----------------------------------------------------\n",
        "\n",
        "  if answer == \"Poisson\":\n",
        "\n",
        "    integer_data = [x for x in data if float(x).is_integer()]\n",
        "    estimated_lambda = np.mean(integer_data) if integer_data else 3.0\n",
        "\n",
        "    print(f\"Suggested lambda (from integer data): {estimated_lambda:.2f}\")\n",
        "    while True:\n",
        "        try:\n",
        "            lambda_val = float(input(\"Enter the Poisson mean (lambda): \"))\n",
        "            if lambda_val > 0:\n",
        "                break\n",
        "            else:\n",
        "                print(\"lambda must be greater than 0.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x):\n",
        "      if x >= 0 and float(x).is_integer():\n",
        "          x_int = int(x)\n",
        "          # Use log-likelihood to avoid overflow with large numbers\n",
        "          log_pdf = -lambda_val + x_int * math.log(lambda_val) - math.lgamma(x_int + 1)\n",
        "          return math.exp(log_pdf)\n",
        "      else:\n",
        "          return 0\n",
        "\n",
        "    return pdf, (lambda_val,)\n",
        "\n",
        "  if answer == \"Bernoulli\":\n",
        "    while True:\n",
        "        try:\n",
        "            p = float(input(\"Enter probability of success (0 < p < 1): \"))\n",
        "            if 0 < p < 1:\n",
        "                break\n",
        "            else:\n",
        "                print(\"p must be between 0 and 1.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    def pdf(x):\n",
        "        return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "\n",
        "    return pdf, (p,)\n",
        "\n",
        "  if answer == \"Binomial\":\n",
        "    n= max(data)\n",
        "    while True:\n",
        "        try:\n",
        "            p = float(input(\"Enter probability of success (0 < p < 1): \"))\n",
        "            if 0 < p < 1:\n",
        "                break\n",
        "            else:\n",
        "                print(\"0 < p < 1.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a positive number.\")\n",
        "    def pdf(x):\n",
        "      if 0 <= x <= n:\n",
        "          return math.comb(n, x) * (p ** x) * ((1 - p) ** (n - x))\n",
        "      else:\n",
        "          return 0\n",
        "\n",
        "    return pdf, (n, p)\n",
        "\n",
        "def update_pdfs(components):\n",
        "    for comp in components:\n",
        "        name = comp[\"distr name\"]\n",
        "        params = comp[\"params\"]\n",
        "\n",
        "        if name == \"Normal\":\n",
        "            mu, sigma = params\n",
        "            def f(x, mu=mu, sigma=sigma):\n",
        "                return (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(-(x - mu)**2 / (2 * sigma**2))\n",
        "            comp[\"pdf\"] = f\n",
        "\n",
        "        elif name == \"Poisson\":\n",
        "            lamb = params[0]\n",
        "            def f(x, lamb=lamb):\n",
        "                if x >= 0 and float(x).is_integer():\n",
        "                    x_int = int(x)\n",
        "                    # Use log-likelihood to avoid overflow with large numbers\n",
        "                    log_pdf = -lamb + x_int * math.log(lamb) - math.lgamma(x_int + 1)\n",
        "                    return math.exp(log_pdf)\n",
        "                else:\n",
        "                  return 0\n",
        "            comp[\"pdf\"] = f\n",
        "\n",
        "        elif name == \"Exponential\":\n",
        "            theta = params[0]\n",
        "            def f(x, theta=theta):\n",
        "                return (1 / theta) * math.exp(-x / theta) if x >= 0 else 0\n",
        "            comp[\"pdf\"] = f\n",
        "\n",
        "        elif name == \"Uniform\":\n",
        "            a, b = params\n",
        "            def f(x, a=a, b=b):\n",
        "                return 1 / (b - a) if a <= x <= b else 0\n",
        "            comp[\"pdf\"] = f\n",
        "\n",
        "        elif name == \"Bernoulli\":\n",
        "            p = params[0]\n",
        "            def f(x, p=p):\n",
        "                return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "            comp[\"pdf\"] = f\n",
        "        elif name == \"Binomial\":\n",
        "          n, p = params\n",
        "          def f(x):\n",
        "            if 0 <= x <= n:\n",
        "              return math.comb(n, x) * (p ** x) * ((1 - p) ** (n - x))\n",
        "            else:\n",
        "              return 0\n",
        "          comp[\"pdf\"] = f\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown distribution name: {name}\")\n",
        "\n",
        "def e_step(data, components):\n",
        "  responsibilities = []\n",
        "  for x in data:\n",
        "    num = [comp[\"pi\"] * comp[\"pdf\"](x) for comp in components]\n",
        "    tot = sum(num)\n",
        "    if tot == 0:\n",
        "      probs = [1 / len(components)] * len(components)\n",
        "    else:\n",
        "      probs = [n / tot for n in num]\n",
        "    responsibilities.append(probs)\n",
        "  return responsibilities\n",
        "\n",
        "\n",
        "\n",
        "def m_step(data, responsibilities, components):\n",
        "    n = len(data)\n",
        "    k = len(components)\n",
        "\n",
        "    for i in range(k):\n",
        "        r_i = [resp[i] for resp in responsibilities]\n",
        "        total_r = sum(r_i)\n",
        "        components[i][\"pi\"] = total_r / n if total_r > 0 else 1e-6\n",
        "\n",
        "        spec_data = [x * r for x, r in zip(data, r_i)]\n",
        "\n",
        "        if components[i][\"distr name\"] == \"Uniform\":\n",
        "            # Weighted min/max\n",
        "            weights = np.array(r_i)\n",
        "            if np.sum(weights) > 0:\n",
        "                x_array = np.array(data)\n",
        "                components[i][\"params\"] = (np.min(x_array[weights > 0]), np.max(x_array[weights > 0]))\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "\n",
        "        elif components[i][\"distr name\"] == \"Exponential\":\n",
        "            if total_r > 0:\n",
        "                theta = sum(spec_data) / total_r\n",
        "                components[i][\"params\"] = (theta,)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "\n",
        "        elif components[i][\"distr name\"] == \"Normal\":\n",
        "            if total_r > 0:\n",
        "                mu = sum(spec_data) / total_r\n",
        "                var = sum(r * ((x - mu)**2) for x, r in zip(data, r_i)) / total_r\n",
        "                sigma = math.sqrt(var)\n",
        "                components[i][\"params\"] = (mu, sigma)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "\n",
        "        elif components[i][\"distr name\"] == \"Bernoulli\":\n",
        "            if total_r > 0:\n",
        "                p = sum(spec_data) / total_r\n",
        "                components[i][\"params\"] = (p,)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "\n",
        "        elif components[i][\"distr name\"] == \"Poisson\":\n",
        "            if total_r > 0:\n",
        "                lambda_ = sum(spec_data) / total_r\n",
        "                components[i][\"params\"] = (lambda_,)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "        elif components[i][\"distr name\"] == \"Binomial\":\n",
        "\n",
        "            n_old, p = components[i][\"params\"]\n",
        "            n_int = int(n_old)  # fixed initial n\n",
        "\n",
        "            total_r = sum(r_i)\n",
        "            if total_r > 0:\n",
        "              weighted_sum = sum(x * r for x, r in zip(data, r_i))\n",
        "              p_estimate = weighted_sum / (n_int * total_r)\n",
        "              p_estimate = max(1e-6, min(1 - 1e-6, p_estimate))\n",
        "              components[i][\"params\"] = (n_int, p_estimate)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown distribution name: {components[i]['distr name']}\")\n",
        "\n",
        "\n",
        "    update_pdfs(components)\n",
        "    return components\n",
        "\n",
        "\n",
        "def compute_log_likelihood(data, components):\n",
        "    log_likelihood = 0\n",
        "    for x in data:\n",
        "        mixture_prob = sum(comp['pi'] * comp['pdf'](x) for comp in components)\n",
        "        if mixture_prob > 0:\n",
        "            log_likelihood += np.log(mixture_prob)\n",
        "    return log_likelihood\n",
        "\n",
        "\n",
        "def EM_MCMC(data, num_iters):\n",
        "\n",
        "  components = []\n",
        "\n",
        "  # data = [0, 1, 8, 6, 2, 4] # Removed hardcoded data\n",
        "\n",
        "  num_components = int(input(\"How many distributions would you like to mix? \"))\n",
        "\n",
        "  components = []\n",
        "  for i in range(num_components):\n",
        "    distr = ''\n",
        "    while distr not in [\"Uniform\", \"Exponential\", \"Normal\", \"Poisson\", \"Bernoulli\", \"Binomial\"]:\n",
        "      distr = input(f\"Choose distribution {i+1}: \")\n",
        "    pdf_f, param = pick_distribution(distr)\n",
        "    components.append({\"distr name\": distr, \"pdf\": pdf_f, \"params\": param, \"pi\": 1 / num_components}) # --> Start by assuming that each data point has equal\n",
        "                                                                                                          # chance of being associated with one of the distributions.\n",
        "  ll_list = []\n",
        "  for i in range(num_iters):\n",
        "    responsibilities = e_step(data, components)\n",
        "    components = m_step(data, responsibilities, components)\n",
        "\n",
        "    ll = compute_log_likelihood(data, components)\n",
        "    ll_list.append(ll)\n",
        "    if i > 0:\n",
        "      print(f\"Iteration {i+1}: Log-likelihood = {ll}\")\n",
        "\n",
        "  # plot log likelihood changes\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.scatter(range(len(ll_list)), ll_list, label='Data')\n",
        "\n",
        "  coeffs = np.polyfit(range(len(ll_list)), ll_list, deg=3)\n",
        "  trendline = np.poly1d(coeffs)\n",
        "\n",
        "  plt.plot(range(len(ll_list)), trendline(range(len(ll_list))), color='blue', label='Trendline')\n",
        "\n",
        "  plt.xlabel(\"iteration\")\n",
        "  plt.ylabel(\"log likelihood\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Final parameters:\")\n",
        "\n",
        "  for i in range(len(components)):\n",
        "    print(f\"Component {i+1}: {components[i]['distr name']}\")\n",
        "    print(\"Parameters:\", *(float(x) for x in components[i]['params']))\n",
        "    print(f\"Weight: {float(components[i]['pi'])}\")\n",
        "    print()\n",
        "  return\n",
        "\n",
        "np.random.seed(924)\n",
        "\n",
        "# Generate data\n",
        "n = 300\n",
        "data = []\n",
        "\n",
        "# 40% Normal(2, 0.5)\n",
        "#data += list(np.random.normal(loc=2, scale=0.5, size=int(0.4 * n)))\n",
        "\n",
        "data += list(np.random.poisson(3, size=int(0.4 * n)))\n",
        "data += list(np.random.binomial(300, 0.5, size=int(0.6 * n)))\n",
        "\n",
        "# 30% Uniform(0,5)\n",
        "#data += list(np.random.uniform(0,5, size=int(0.3 * n)))\n",
        "\n",
        "# 30% Exponential(1.5)\n",
        "#data += list(np.random.exponential(scale=1.5, size=int(0.3 * n)))\n",
        "\n",
        "\n",
        "random.shuffle(data)\n",
        "\n",
        "\n",
        "EM_MCMC(data, 200)"
      ],
      "metadata": {
        "id": "ppNttsz4YIh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OLD VERSIONS BEFORE CHATGPT CLEAN UP"
      ],
      "metadata": {
        "id": "j0ooQs3Y0_f1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EM NORMAL"
      ],
      "metadata": {
        "id": "Bmb-qy7Q1DeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import functools\n",
        "\n",
        "def pick_distribution(answer):\n",
        "\n",
        "  #Continuous Distributions-----------------------------------------------------\n",
        "\n",
        "  if answer == \"Uniform\":\n",
        "    while True:\n",
        "      try:\n",
        "        a0 = float(input(\"Initial lower bound guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    while True:\n",
        "      try:\n",
        "        b0 = float(input(\"Initial upper bound guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x):\n",
        "      return 1 / (b0 - a0) if a0 <= x <= b0 else 0\n",
        "\n",
        "    return pdf, (a0, b0)\n",
        "\n",
        "  if answer == \"Exponential\":\n",
        "    while True:\n",
        "      try:\n",
        "        theta0 = float(input(\"Enter the mean guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    def pdf(x):\n",
        "      return (1 / theta0) * math.exp(-x / theta0) if x >= 0 else 0\n",
        "\n",
        "    return pdf, (theta0,) # Corrected parameter return\n",
        "\n",
        "  if answer == \"Normal\":\n",
        "    while True:\n",
        "      try:\n",
        "        mu0 = float(input(\"Enter the mean guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    while True:\n",
        "      try:\n",
        "        sigma0 = float(input(\"Enter the standard deviation guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x_val):\n",
        "      return (1 / (sigma0 * math.sqrt(2 * math.pi))) * math.exp(-(x_val - mu0)**2 / (2 * sigma0**2))\n",
        "    return pdf, (mu0, sigma0)\n",
        "\n",
        "\n",
        "  #Discrete Distributions-----------------------------------------------------\n",
        "\n",
        "  if answer == \"Poisson\":\n",
        "\n",
        "    integer_data = [x for x in data if float(x).is_integer()]\n",
        "    estimated_lambda = np.mean(integer_data) if integer_data else 3.0\n",
        "\n",
        "    print(f\"Suggested lambda (from integer data): {estimated_lambda:.2f}\")\n",
        "    while True:\n",
        "        try:\n",
        "            lambda_val = float(input(\"Enter the Poisson mean (lambda): \"))\n",
        "            if lambda_val > 0:\n",
        "                break\n",
        "            else:\n",
        "                print(\"lambda must be greater than 0.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x):\n",
        "      if x >= 0 and float(x).is_integer():\n",
        "          x_int = int(x)\n",
        "          # Use log-likelihood to avoid overflow with large numbers\n",
        "          log_pdf = -lambda_val + x_int * math.log(lambda_val) - math.lgamma(x_int + 1)\n",
        "          return math.exp(log_pdf)\n",
        "      else:\n",
        "          return 0\n",
        "\n",
        "    return pdf, (lambda_val,)\n",
        "\n",
        "  if answer == \"Bernoulli\":\n",
        "    while True:\n",
        "        try:\n",
        "            p = float(input(\"Enter probability of success (0 < p < 1): \"))\n",
        "            if 0 < p < 1:\n",
        "                break\n",
        "            else:\n",
        "                print(\"p must be between 0 and 1.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    def pdf(x):\n",
        "        return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "\n",
        "    return pdf, (p,)\n",
        "\n",
        "  if answer == \"Binomial\":\n",
        "    n= max(data)\n",
        "    while True:\n",
        "        try:\n",
        "            p = float(input(\"Enter probability of success (0 < p < 1): \"))\n",
        "            if 0 < p < 1:\n",
        "                break\n",
        "            else:\n",
        "                print(\"0 < p < 1.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a positive number.\")\n",
        "    def pdf(x):\n",
        "      if 0 <= x <= n:\n",
        "          return math.comb(n, x) * (p ** x) * ((1 - p) ** (n - x))\n",
        "      else:\n",
        "          return 0\n",
        "\n",
        "    return pdf, (n, p)\n",
        "\n",
        "def update_pdfs(components):\n",
        "    for comp in components:\n",
        "        name = comp[\"distr name\"]\n",
        "        params = comp[\"params\"]\n",
        "\n",
        "        if name == \"Normal\":\n",
        "            mu, sigma = params\n",
        "            def f(x, mu=mu, sigma=sigma):\n",
        "                return (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(-(x - mu)**2 / (2 * sigma**2))\n",
        "            comp[\"pdf\"] = f\n",
        "\n",
        "        elif name == \"Poisson\":\n",
        "            lamb = params[0]\n",
        "            def f(x, lamb=lamb):\n",
        "                if x >= 0 and float(x).is_integer():\n",
        "                    x_int = int(x)\n",
        "                    # Use log-likelihood to avoid overflow with large numbers\n",
        "                    log_pdf = -lamb + x_int * math.log(lamb) - math.lgamma(x_int + 1)\n",
        "                    return math.exp(log_pdf)\n",
        "                else:\n",
        "                  return 0\n",
        "            comp[\"pdf\"] = f\n",
        "\n",
        "        elif name == \"Exponential\":\n",
        "            theta = params[0]\n",
        "            def f(x, theta=theta):\n",
        "                return (1 / theta) * math.exp(-x / theta) if x >= 0 else 0\n",
        "            comp[\"pdf\"] = f\n",
        "\n",
        "        elif name == \"Uniform\":\n",
        "            a, b = params\n",
        "            def f(x, a=a, b=b):\n",
        "                return 1 / (b - a) if a <= x <= b else 0\n",
        "            comp[\"pdf\"] = f\n",
        "\n",
        "        elif name == \"Bernoulli\":\n",
        "            p = params[0]\n",
        "            def f(x, p=p):\n",
        "                return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "            comp[\"pdf\"] = f\n",
        "        elif name == \"Binomial\":\n",
        "          n, p = params\n",
        "          def f(x):\n",
        "            if 0 <= x <= n:\n",
        "              return math.comb(n, x) * (p ** x) * ((1 - p) ** (n - x))\n",
        "            else:\n",
        "              return 0\n",
        "          comp[\"pdf\"] = f\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown distribution name: {name}\")\n",
        "\n",
        "def e_step(data, components):\n",
        "  responsibilities = []\n",
        "  for x in data:\n",
        "    num = [comp[\"pi\"] * comp[\"pdf\"](x) for comp in components]\n",
        "    tot = sum(num)\n",
        "    if tot == 0:\n",
        "      probs = [1 / len(components)] * len(components)\n",
        "    else:\n",
        "      probs = [n / tot for n in num]\n",
        "    responsibilities.append(probs)\n",
        "  return responsibilities\n",
        "\n",
        "\n",
        "\n",
        "def m_step(data, responsibilities, components):\n",
        "    n = len(data)\n",
        "    k = len(components)\n",
        "\n",
        "    for i in range(k):\n",
        "        r_i = [resp[i] for resp in responsibilities]\n",
        "        total_r = sum(r_i)\n",
        "        components[i][\"pi\"] = total_r / n if total_r > 0 else 1e-6\n",
        "\n",
        "        spec_data = [x * r for x, r in zip(data, r_i)]\n",
        "\n",
        "        name = components[i][\"distr name\"]\n",
        "\n",
        "        if name == \"Uniform\":\n",
        "          if np.sum(r_i) > 0:\n",
        "              x_array = np.array(data)\n",
        "              r_array = np.array(r_i)\n",
        "              # Filter to data with reasonably high responsibility (e.g., top 80%)\n",
        "              cutoff = np.percentile(r_array, 80)\n",
        "              relevant_data = x_array[r_array >= cutoff]\n",
        "              if len(relevant_data) >= 2:\n",
        "                  a_est = np.min(relevant_data)\n",
        "                  b_est = np.max(relevant_data)\n",
        "              else:\n",
        "                  # Fallback in case too few data points\n",
        "                  a_est = np.min(x_array)\n",
        "                  b_est = np.max(x_array)\n",
        "              components[i][\"params\"] = (a_est, b_est)\n",
        "          else:\n",
        "              pass # Keep previous parameters if no data points assigned to this component\n",
        "\n",
        "        elif components[i][\"distr name\"] == \"Exponential\":\n",
        "            if total_r > 0:\n",
        "                theta = sum(spec_data) / total_r\n",
        "                components[i][\"params\"] = (theta,)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "\n",
        "        elif components[i][\"distr name\"] == \"Normal\":\n",
        "            if total_r > 0:\n",
        "                mu = sum(spec_data) / total_r\n",
        "                var = sum(r * ((x - mu)**2) for x, r in zip(data, r_i)) / total_r\n",
        "                sigma = math.sqrt(var)\n",
        "                components[i][\"params\"] = (mu, sigma)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "\n",
        "        elif components[i][\"distr name\"] == \"Bernoulli\":\n",
        "            if total_r > 0:\n",
        "                p = sum(spec_data) / total_r\n",
        "                components[i][\"params\"] = (p,)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "\n",
        "        elif components[i][\"distr name\"] == \"Poisson\":\n",
        "            if total_r > 0:\n",
        "                lambda_ = sum(spec_data) / total_r\n",
        "                components[i][\"params\"] = (lambda_,)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "        elif components[i][\"distr name\"] == \"Binomial\":\n",
        "\n",
        "            n_old, p = components[i][\"params\"]\n",
        "            n_int = int(n_old)  # fixed initial n\n",
        "\n",
        "            total_r = sum(r_i)\n",
        "            if total_r > 0:\n",
        "              weighted_sum = sum(x * r for x, r in zip(data, r_i))\n",
        "              p_estimate = weighted_sum / (n_int * total_r)\n",
        "              p_estimate = max(1e-6, min(1 - 1e-6, p_estimate))\n",
        "              components[i][\"params\"] = (n_int, p_estimate)\n",
        "            else:\n",
        "                pass # Keep previous parameters if no data points assigned to this component\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown distribution name: {components[i]['distr name']}\")\n",
        "\n",
        "\n",
        "    update_pdfs(components)\n",
        "    return components\n",
        "\n",
        "\n",
        "def compute_log_likelihood(data, components):\n",
        "    log_likelihood = 0\n",
        "    for x in data:\n",
        "        mixture_prob = sum(comp['pi'] * comp['pdf'](x) for comp in components)\n",
        "        if mixture_prob > 0:\n",
        "            log_likelihood += np.log(mixture_prob)\n",
        "    return log_likelihood\n",
        "\n",
        "\n",
        "def EM_MCMC(data, num_iters):\n",
        "\n",
        "  components = []\n",
        "\n",
        "  # data = [0, 1, 8, 6, 2, 4] # Removed hardcoded data\n",
        "\n",
        "  num_components = int(input(\"How many distributions would you like to mix? \"))\n",
        "\n",
        "  components = []\n",
        "  for i in range(num_components):\n",
        "    distr = ''\n",
        "    while distr not in [\"Uniform\", \"Exponential\", \"Normal\", \"Poisson\", \"Bernoulli\", \"Binomial\"]:\n",
        "      distr = input(f\"Choose distribution {i+1}: \")\n",
        "    pdf_f, param = pick_distribution(distr)\n",
        "    components.append({\"distr name\": distr, \"pdf\": pdf_f, \"params\": param, \"pi\": 1 / num_components}) # --> Start by assuming that each data point has equal\n",
        "                                                                                                          # chance of being associated with one of the distributions.\n",
        "  ll_list = []\n",
        "  for i in range(num_iters):\n",
        "    responsibilities = e_step(data, components)\n",
        "    components = m_step(data, responsibilities, components)\n",
        "\n",
        "    ll = compute_log_likelihood(data, components)\n",
        "    ll_list.append(ll)\n",
        "    if i > 0:\n",
        "      print(f\"Iteration {i+1}: Log-likelihood = {ll}\")\n",
        "\n",
        "  # plot log likelihood changes\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.scatter(range(len(ll_list)), ll_list, label='Data')\n",
        "\n",
        "  coeffs = np.polyfit(range(len(ll_list)), ll_list, deg=3)\n",
        "  trendline = np.poly1d(coeffs)\n",
        "\n",
        "  plt.plot(range(len(ll_list)), trendline(range(len(ll_list))), color='blue', label='Trendline')\n",
        "\n",
        "  plt.xlabel(\"iteration\")\n",
        "  plt.ylabel(\"log likelihood\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Final parameters:\")\n",
        "\n",
        "  for i in range(len(components)):\n",
        "    print(f\"Component {i+1}: {components[i]['distr name']}\")\n",
        "    print(\"Parameters:\", *(float(x) for x in components[i]['params']))\n",
        "    print(f\"Weight: {float(components[i]['pi'])}\")\n",
        "    print()\n",
        "  return\n",
        "\n",
        "np.random.seed(924)\n",
        "\n",
        "# Generate data\n",
        "n = 300\n",
        "data = []\n",
        "\n",
        "# 40% Normal(2, 0.5)\n",
        "data += list(np.random.normal(loc=2, scale=0.5, size=int(0.4 * n)))\n",
        "\n",
        "#data += list(np.random.poisson(3, size=int(0.4 * n)))\n",
        "#data += list(np.random.binomial(300, 0.5, size=int(0.6 * n)))\n",
        "\n",
        "# 30% Uniform(0,5)\n",
        "data += list(np.random.uniform(0,5, size=int(0.3 * n)))\n",
        "\n",
        "# 30% Exponential(1.5)\n",
        "data += list(np.random.exponential(scale=1.5, size=int(0.3 * n)))\n",
        "\n",
        "\n",
        "random.shuffle(data)\n",
        "\n",
        "\n",
        "EM_MCMC(data, 200)"
      ],
      "metadata": {
        "id": "txUN3KVI0-ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "New NEW NEW"
      ],
      "metadata": {
        "id": "LUfCWPwz_qCs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i04f5JkA_rvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EMMC"
      ],
      "metadata": {
        "id": "pJMP-eyt1PgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import functools\n",
        "\n",
        "def pick_distribution(answer):\n",
        "\n",
        "  #Continuous Distributions-----------------------------------------------------\n",
        "\n",
        "  if answer == \"Uniform\":\n",
        "    while True:\n",
        "      try:\n",
        "        a0 = float(input(\"Initial lower bound guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    while True:\n",
        "      try:\n",
        "        b0 = float(input(\"Initial upper bound guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x):\n",
        "      return 1 / (b0 - a0) if a0 <= x <= b0 else 0\n",
        "\n",
        "    return pdf, (a0, b0)\n",
        "\n",
        "  if answer == \"Exponential\":\n",
        "    while True:\n",
        "      try:\n",
        "        theta0 = float(input(\"Enter the mean guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    def pdf(x):\n",
        "      return (1 / theta0) * math.exp(-x / theta0) if x >= 0 else 0\n",
        "\n",
        "    return pdf, (theta0,) # Corrected parameter return\n",
        "\n",
        "  if answer == \"Normal\":\n",
        "    while True:\n",
        "      try:\n",
        "        mu0 = float(input(\"Enter the mean guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    while True:\n",
        "      try:\n",
        "        sigma0 = float(input(\"Enter the standard deviation guess: \"))\n",
        "        break\n",
        "      except ValueError:\n",
        "        print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x_val):\n",
        "      return (1 / (sigma0 * math.sqrt(2 * math.pi))) * math.exp(-(x_val - mu0)**2 / (2 * sigma0**2))\n",
        "    return pdf, (mu0, sigma0)\n",
        "\n",
        "\n",
        "  #Discrete Distributions-----------------------------------------------------\n",
        "\n",
        "  if answer == \"Poisson\":\n",
        "\n",
        "    integer_data = [x for x in data if float(x).is_integer()]\n",
        "    estimated_lambda = np.mean(integer_data) if integer_data else 3.0\n",
        "\n",
        "    print(f\"Suggested lambda (from integer data): {estimated_lambda:.2f}\")\n",
        "    while True:\n",
        "        try:\n",
        "            lambda_val = float(input(\"Enter the Poisson mean (lambda): \"))\n",
        "            if lambda_val > 0:\n",
        "                break\n",
        "            else:\n",
        "                print(\"lambda must be greater than 0.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "    def pdf(x):\n",
        "      if x >= 0 and float(x).is_integer():\n",
        "          x_int = int(x)\n",
        "          # Use log-likelihood to avoid overflow with large numbers\n",
        "          log_pdf = -lambda_val + x_int * math.log(lambda_val) - math.lgamma(x_int + 1)\n",
        "          return math.exp(log_pdf)\n",
        "      else:\n",
        "          return 0\n",
        "\n",
        "    return pdf, (lambda_val,)\n",
        "\n",
        "  if answer == \"Bernoulli\":\n",
        "    while True:\n",
        "        try:\n",
        "            p = float(input(\"Enter probability of success (0 < p < 1): \"))\n",
        "            if 0 < p < 1:\n",
        "                break\n",
        "            else:\n",
        "                print(\"p must be between 0 and 1.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    def pdf(x):\n",
        "        return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "\n",
        "    return pdf, (p,)\n",
        "\n",
        "  if answer == \"Binomial\":\n",
        "    n= 100000000000\n",
        "    while True:\n",
        "        try:\n",
        "            p = float(input(\"Enter probability of success (0 < p < 1): \"))\n",
        "            if 0 < p < 1:\n",
        "                break\n",
        "            else:\n",
        "                print(\"0 < p < 1.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a positive number.\")\n",
        "    def pdf(x):\n",
        "      if 0 <= x <= n:\n",
        "          return math.comb(n, x) * (p ** x) * ((1 - p) ** (n - x))\n",
        "      else:\n",
        "          return 0\n",
        "\n",
        "    return pdf, (n, p)\n",
        "\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def e_step_MCMC(data, components, steps = 100):\n",
        "  n = len(data)\n",
        "  k = len(components)\n",
        "\n",
        "  z_samples = []\n",
        "\n",
        "  for i in range(n):\n",
        "    x = data[i]\n",
        "\n",
        "    weights = [comp[\"pi\"] * comp[\"pdf\"](x) for comp in components]\n",
        "    total = sum(weights)\n",
        "\n",
        "    if total == 0:\n",
        "      weights = [1 / k] * k\n",
        "    else:\n",
        "      weights = [w / total for w in weights]\n",
        "    z = np.random.choice(range(k), p=weights)\n",
        "\n",
        "    chain = []\n",
        "\n",
        "    for t in range(steps):\n",
        "      if k > 1: # Add check for k > 1\n",
        "        z_new = np.random.choice([j for j in range(k) if j != z])\n",
        "\n",
        "        if components[z_new][\"distr name\"] in {\"Poisson\", \"Bernoulli\", \"Binomial\"} and not float(x).is_integer():\n",
        "          chain.append(z)\n",
        "          continue\n",
        "\n",
        "\n",
        "        num = components[z_new][\"pi\"] * components[z_new][\"pdf\"](x) # Score function which will idealize the data point with a certain distribution if the associated pi and pdf value\n",
        "        den = components[z][\"pi\"] * components[z][\"pdf\"](x)         # with the data point is more than that of the previous\n",
        "\n",
        "        alpha = min(1, num / den if den > 0 else 1)\n",
        "\n",
        "        if np.random.rand() < alpha:\n",
        "          z = z_new\n",
        "\n",
        "      chain.append(z)\n",
        "\n",
        "    z_samples.append(chain)\n",
        "\n",
        "  return z_samples\n",
        "\n",
        "def m_step_MCMC(z_samples, components):\n",
        "\n",
        "  n = len(data)\n",
        "  k = len(components)\n",
        "\n",
        "  flatz = [z for chain in z_samples for z in chain]\n",
        "\n",
        "  total = len(flatz)\n",
        "\n",
        "  eps = 1e-6\n",
        "  min_weight = 0.05\n",
        "\n",
        "  for i in range(k):\n",
        "    count_i = flatz.count(i)\n",
        "    pi_i = (count_i + eps) / (total)\n",
        "    components[i][\"pi\"] =  max(min_weight, pi_i)  # Updates pi / how much each distribution is mixed with how many exposures we got of the the specific distribution for all the data samples / total\n",
        "                                                 # we give (count_i + e-6) for the case when our samples got us no cases when the data point was associated with pi_i distribution. This would make it so\n",
        "                                                    # that theres no chance for the distribution to be revived no matter the pdf we got exposed to in the e step.\n",
        "\n",
        "  new_total = sum(comp[\"pi\"] for comp in components)\n",
        "\n",
        "  for i in range(k):\n",
        "    components[i][\"pi\"] /= new_total # normalizing because of min_weight\n",
        "\n",
        "  return components\n",
        "\n",
        "def update_params_pdfs(data, components, z_samples):\n",
        "  k = len(components)\n",
        "  n = len(data)\n",
        "\n",
        "  flat_x = [x for i, x in enumerate(data) for j in range(len(z_samples[i]))]\n",
        "  flat_z = [z for chain in z_samples for z in chain]\n",
        "\n",
        "  for i in range(len(components)):\n",
        "      print(f\"Component {i}: {components[i]['distr name']}, count = {flat_z.count(i)}\")\n",
        "\n",
        "  print()\n",
        "\n",
        "  for i in range(k):\n",
        "\n",
        "    spec_data  = [x for x, z in zip(flat_x, flat_z) if z == i] # filters data points into what distribution we think the data points are associated with\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Uniform\":\n",
        "      if spec_data: # Add check for empty list\n",
        "        components[i][\"params\"] = (min(spec_data), max(spec_data))\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Exponential\":\n",
        "      if spec_data: # Add check for empty list\n",
        "        components[i][\"params\"] = (np.mean(spec_data),)\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Normal\":\n",
        "      if spec_data: # Add check for empty list\n",
        "        components[i][\"params\"] = (np.mean(spec_data), np.std(spec_data))\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Bernoulli\":\n",
        "      if spec_data:\n",
        "        components[i][\"params\"] = (np.mean(spec_data),)\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "    if components[i][\"distr name\"] == \"Poisson\":\n",
        "      if spec_data:\n",
        "        components[i][\"params\"] = (np.mean(spec_data),)\n",
        "      else:\n",
        "        pass\n",
        "    if components[i][\"distr name\"] == \"Binomial\":\n",
        "        if spec_data:\n",
        "          n_old, p = components[i][\"params\"]\n",
        "\n",
        "          n_int = int(n) if isinstance(n, (int, float)) else n\n",
        "\n",
        "          n = max(n_int, int(np.percentile(spec_data, 95)))\n",
        "\n",
        "          p_estimate = (np.mean(spec_data) / n_int) if n_int > 0 and np.mean(spec_data) > 0 else 1e-6\n",
        "          # Ensure p is within (0, 1)\n",
        "          p_estimate = max(1e-6, min(1 - 1e-6, p_estimate))\n",
        "          components[i][\"params\"] = (n_int, p_estimate)\n",
        "        else:\n",
        "          pass\n",
        "\n",
        "\n",
        "  for comp in components:\n",
        "      name = comp[\"distr name\"]\n",
        "      params = comp[\"params\"]\n",
        "\n",
        "      if name == \"Normal\":\n",
        "        if len(spec_data) > 5:\n",
        "          mu, sigma = params\n",
        "          def f(x, mu=mu, sigma=sigma):\n",
        "              return (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(-(x - mu)**2 / (2 * sigma**2))\n",
        "          comp[\"pdf\"] = f\n",
        "      elif name == \"Poisson\":\n",
        "          lamb = params[0]\n",
        "          def f(x, lamb=lamb):\n",
        "              if x >= 0 and float(x).is_integer():\n",
        "                  x_int = int(x)\n",
        "                  # Use log-likelihood to avoid overflow with large numbers\n",
        "                  log_pdf = -lamb + x_int * math.log(lamb) - math.lgamma(x_int + 1)\n",
        "                  return math.exp(log_pdf)\n",
        "              else:\n",
        "                  return 0\n",
        "          comp[\"pdf\"] = f\n",
        "      elif name == \"Exponential\":\n",
        "          theta = params[0]\n",
        "          def f(x, theta=theta):\n",
        "              return (1 / theta) * math.exp(-x / theta) if x >= 0 else 0\n",
        "          comp[\"pdf\"] = f\n",
        "      elif name == \"Uniform\":\n",
        "          a, b = params\n",
        "          def f(x, a=a, b=b):\n",
        "              return 1 / (b - a) if a <= x <= b else 0\n",
        "          comp[\"pdf\"] = f\n",
        "      elif name == \"Bernoulli\":\n",
        "          p = params[0]\n",
        "          def f(x, p=p):\n",
        "              return p if x == 1 else (1 - p) if x == 0 else 0\n",
        "          comp[\"pdf\"] = f\n",
        "      elif name == \"Binomial\":\n",
        "        n, p = params\n",
        "        def f(x):\n",
        "          if 0 <= x <= n:\n",
        "            return math.comb(n, x) * (p ** x) * ((1 - p) ** (n - x))\n",
        "          else:\n",
        "            return 0\n",
        "        comp[\"pdf\"] = f\n",
        "      else:\n",
        "        raise ValueError(f\"Unknown distribution name: {name}\")\n",
        "  return components\n",
        "\n",
        "def compute_log_likelihood(data, components):\n",
        "    log_likelihood = 0\n",
        "    for x in data:\n",
        "        mixture_prob = sum(comp['pi'] * comp['pdf'](x) for comp in components)\n",
        "        if mixture_prob > 0:\n",
        "            log_likelihood += np.log(mixture_prob)\n",
        "    return log_likelihood\n",
        "\n",
        "\n",
        "def EM_MCMC(data, num_iters):\n",
        "\n",
        "  components = []\n",
        "\n",
        "  # data = [0, 1, 8, 6, 2, 4] # Removed hardcoded data\n",
        "\n",
        "  num_components = int(input(\"How many distributions would you like to mix? \"))\n",
        "\n",
        "  components = []\n",
        "  for i in range(num_components):\n",
        "    distr = ''\n",
        "    while distr not in [\"Uniform\", \"Exponential\", \"Normal\", \"Poisson\", \"Bernoulli\", \"Binomial\"]:\n",
        "      distr = input(f\"Choose distribution {i+1}: \")\n",
        "    pdf_f, param = pick_distribution(distr)\n",
        "    components.append({\"distr name\": distr, \"pdf\": pdf_f, \"params\": param, \"pi\": 1 / num_components}) # --> Start by assuming that each data point has equal\n",
        "                                                                                                          # chance of being associated with one of the distributions.\n",
        "  ll_list = []\n",
        "  for i in range(num_iters):\n",
        "    z_samples = e_step_MCMC(data, components) #\n",
        "    components = m_step_MCMC(z_samples, components)\n",
        "    components = update_params_pdfs(data, components, z_samples)\n",
        "\n",
        "    ll = compute_log_likelihood(data, components)\n",
        "    ll_list.append(ll)\n",
        "    if i > 0:\n",
        "      print(f\"Iteration {i+1}: Log-likelihood = {ll}\")\n",
        "\n",
        "  # plot log likelihood changes\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.scatter(range(len(ll_list)), ll_list, label='Data')\n",
        "\n",
        "  coeffs = np.polyfit(range(len(ll_list)), ll_list, deg=3)\n",
        "  trendline = np.poly1d(coeffs)\n",
        "\n",
        "  plt.plot(range(len(ll_list)), trendline(range(len(ll_list))), color='blue', label='Trendline')\n",
        "\n",
        "  plt.xlabel(\"iteration\")\n",
        "  plt.ylabel(\"log likelihood\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  print(\"Final parameters:\")\n",
        "\n",
        "  for i in range(len(components)):\n",
        "    print(f\"Component {i+1}: {components[i]['distr name']}\")\n",
        "    print(\"Parameters:\", *(float(x) for x in components[i]['params']))\n",
        "    print(f\"Weight: {float(components[i]['pi'])}\")\n",
        "    print()\n",
        "  return\n",
        "\n",
        "np.random.seed(924)\n",
        "\n",
        "# Generate data\n",
        "n = 300\n",
        "data = []\n",
        "\n",
        "# 40% Normal(2, 0.5)\n",
        "#data += list(np.random.normal(loc=2, scale=0.5, size=int(0.4 * n)))\n",
        "\n",
        "data += list(np.random.poisson(3, size=int(0.4 * n)))\n",
        "data += list(np.random.binomial(300, 0.5, size=int(0.6 * n)))\n",
        "\n",
        "# 30% Uniform(0,5)\n",
        "#data += list(np.random.uniform(0,5, size=int(0.3 * n)))\n",
        "\n",
        "# 30% Exponential(1.5)\n",
        "#data += list(np.random.exponential(scale=1.5, size=int(0.3 * n)))\n",
        "\n",
        "\n",
        "random.shuffle(data)\n",
        "\n",
        "\n",
        "EM_MCMC(data, 20)"
      ],
      "metadata": {
        "id": "bB-d5ivX1vy2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}